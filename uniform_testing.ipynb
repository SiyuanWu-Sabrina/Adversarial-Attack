{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xueshuxinxing-jz/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from imagenet_dataset import ImageNetDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToPILImage\n",
    "import models.inception_v3_imagenet as inception_v3\n",
    "import models.generators as generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model_path='./checkpoints', no_cuda='False', seed=5, target_count=20, target_label=-1, target_type=0, test_batch_size=50)\n"
     ]
    }
   ],
   "source": [
    "sys.argv = ['uniform_testing.ipynb', \n",
    "            '--no-cuda', 'False',\n",
    "            '--seed', '5', \n",
    "            '--model-path', './checkpoints',\n",
    "            '--test-batch-size', '50',\n",
    "            '--target-count', '20',\n",
    "            '--target-type', '0',\n",
    "            '--target-label', '-1'\n",
    "            ]\n",
    "parser = argparse.ArgumentParser(description='Black-box Adversarial Attack')\n",
    "parser.add_argument('--no-cuda', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=0, metavar='S',\n",
    "                    help='random seed (default: 0)')\n",
    "parser.add_argument('--model-path', default='../../checkpoints',\n",
    "                    help='directory of model for saving checkpoint')\n",
    "parser.add_argument('--test-batch-size', type=int, default=50, metavar='N',\n",
    "                    help='input batch size for testing (default: 50)')\n",
    "parser.add_argument('--target-count', type=int, default=20, metavar='N',\n",
    "                    help='the amount of targets(default: 20)')\n",
    "parser.add_argument('--target-type', type=int, default=0, metavar='N',\n",
    "                    help='the method of choosing target label.\\n0: ini_label + 1;\\n1: all the other labels')\n",
    "parser.add_argument('--target-label', type=int, default=-1, metavar='N',\n",
    "                    help='target label, default: -1, which is (ini_label + 1) % 10')\n",
    "args = parser.parse_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify optimization related parameters\n",
    "LR = 0.05  # learning rate\n",
    "EPOCHS = 20  # total optimization epochs\n",
    "NB_SAMPLE = 1000  # number of samples for adjusting lambda\n",
    "MINI_BATCH = NB_SAMPLE // args.test_batch_size  # number of batches\n",
    "INIT_COST = 1e-3  # initial weight of lambda\n",
    "\n",
    "ATTACK_SUCC_THRESHOLD = 0.99  # attack success threshold\n",
    "PATIENCE = 5  # patience for adjusting lambda, number of mini batches\n",
    "COST_MULTIPLIER = 2  # multiplier for auto-control of weight (COST)\n",
    "COST_MULTIPLIER_UP = COST_MULTIPLIER\n",
    "COST_MULTIPLIER_DOWN = 10 ** 0.5  # changed from 2**1.5 to 10**0.5\n",
    "\n",
    "EARLY_STOP_THRESHOLD = 1.0  # loss threshold for early stop\n",
    "EARLY_STOP_PATIENCE = 5 * PATIENCE  # patience for early stop\n",
    "EPSILON = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_factory(dataset_type = 'ImageNet', no_cuda = False, batch_size = 1):\n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "    if dataset_type == 'Cifar10':\n",
    "        kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "        dataset = torchvision.datasets.CIFAR10(root='./datasets', train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "    elif dataset_type == 'ImageNet':\n",
    "        im_size = 299\n",
    "        mean_arr = (0.5, 0.5, 0.5)\n",
    "        stddev_arr = (0.5, 0.5, 0.5)\n",
    "        dataset = ImageNetDataset(\n",
    "            image_dir='./datasets/imagenet1000',\n",
    "            label_filepath=\"./datasets/imagenet_label.txt\",\n",
    "            transform=transforms.Compose([\n",
    "                transforms.CenterCrop(im_size),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean_arr, stddev_arr)\n",
    "            ]),\n",
    "        )\n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    " \n",
    "\n",
    "def test_attack_success_rate(config, target_model, attack_algorithm, **kwargs):\n",
    "    # sourcery skip: last-if-guard, use-fstring-for-concatenation\n",
    "    \"\"\"This is the unified model for testing attack success rate for adversarial success under a certain configuration.\n",
    "\n",
    "    Args:\n",
    "        config (dictionary): include the attack type(black or white, targeted or untargeted) and other necessary information\n",
    "        target_model: the model to be attacked\n",
    "        data_loader: batch_size = 1\n",
    "    \"\"\"\n",
    "    print(f\"=====Running test on {config.dataset_type} dataset, attacking model {config.target_model}.=====\")\n",
    "    dataloader = data_factory(config.dataset_type)\n",
    "    if config.target_type == 'Untargeted' and config.dataset_type == 'ImageNet':\n",
    "        result = attack_algorithm(target_model, dataloader, config, **kwargs)  # untargeted attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_factory(attack_algorithm):\n",
    "    mapping = {'B3D_w': B3D_attack_white,\n",
    "               'greedyfool_w': greedyfool_attack_white, \n",
    "               'cornersearch_w': cornersearch_attack_white, \n",
    "               'PGD_attack_w': PGD_attack_white, \n",
    "               'homotopy_w': homotopy_attack_white, \n",
    "               'perturbation_w': perturbation_attack_white, \n",
    "               'imperceptible_w': imperceptible_attack_white\n",
    "               }\n",
    "    return mapping[attack_algorithm]\n",
    "\n",
    "def greedyfool_attack_white():\n",
    "    pass\n",
    "\n",
    "def B3D_attack_white():\n",
    "    pass\n",
    "\n",
    "def cornersearch_attack_white():\n",
    "    pass\n",
    "\n",
    "def PGD_attack_white():\n",
    "    pass\n",
    "\n",
    "def homotopy_attack_white():\n",
    "    pass\n",
    "\n",
    "def perturbation_attack_white():\n",
    "    pass\n",
    "\n",
    "def imperceptible_attack_white():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedyfool_attack_white(target_model, test_loader, config, generator):\n",
    "    def clip(adv_A,real_A,eps):\n",
    "        g_x=real_A-adv_A\n",
    "        clip_gx=torch.clamp(g_x, min=-eps, max=eps)\n",
    "        adv_x=real_A-clip_gx\n",
    "        return adv_x\n",
    "    \n",
    "    def CWLoss(logits, target, kappa=0, tar=True):\n",
    "        target = torch.ones(logits.size(0)).type(torch.cuda.FloatTensor).mul(target.float())\n",
    "        target_one_hot = Variable(torch.eye(1000).type(torch.cuda.FloatTensor)[target.long()].cuda())\n",
    "        \n",
    "        real = torch.sum(target_one_hot*logits, 1)\n",
    "        other = torch.max((1-target_one_hot)*logits - (target_one_hot*10000), 1)[0]\n",
    "        kappa = torch.zeros_like(other).fill_(kappa)\n",
    "        \n",
    "        if tar:\n",
    "            return torch.sum(torch.max(other - real, kappa))\n",
    "        else:\n",
    "            return torch.sum(torch.max(real - other, kappa))\n",
    "    \n",
    "    class AverageMeter(object):\n",
    "        \"\"\"Computes and stores the average and current value\"\"\"\n",
    "        def __init__(self):\n",
    "            self.reset()\n",
    "\n",
    "        def reset(self):\n",
    "            self.val = 0\n",
    "            self.avg = 0\n",
    "            self.sum = 0\n",
    "            self.count = 0\n",
    "\n",
    "        def update(self, val, n=1):\n",
    "            self.val = val\n",
    "            self.sum += val * n\n",
    "            self.count += n\n",
    "            self.avg = self.sum / self.count\n",
    "    \n",
    "    pool_kernel = 3\n",
    "    Avg_pool = nn.AvgPool2d(pool_kernel, stride=1, padding=int(pool_kernel/2))\n",
    "    \n",
    "    print(\"Iter {0}\".format(config.iter))\n",
    "    print(\"EPS {0}\".format(config.max_epsilon))\n",
    "    Iter = config.iter\n",
    "    eps = config.max_epsilon * 2 / 255\n",
    "    im_size = config.image_size\n",
    "    root = config.saving_root\n",
    "    \n",
    "    Baccu = []\n",
    "    for i in range(1):\n",
    "        temp_accu = AverageMeter()\n",
    "        Baccu.append(temp_accu)\n",
    "        \n",
    "    num_count = []\n",
    "    time_count = []\n",
    "    if config.max_epsilon >= 128:\n",
    "        boost = False\n",
    "    else:\n",
    "        boost = True\n",
    "    print (\"Boost:{0}\".format(boost))\n",
    "    for idx, data in enumerate(test_loader):\n",
    "        generator.eval()\n",
    "        input_A = data['image']\n",
    "        input_A = input_A.cuda()\n",
    "        real_A = Variable(input_A, requires_grad=False)\n",
    "        image_names = data['name']\n",
    "        \n",
    "        image_hill = generator(real_A * 0.5 + 0.5) * 0.5 + 0.5\n",
    "        pre_hill = 1 - image_hill\n",
    "        pre_hill = pre_hill.view(1, 1, -1)\n",
    "       \n",
    "        np_hill = pre_hill.detach().cpu().numpy()\n",
    "        percen = np.percentile(np_hill, 30)\n",
    "        pre_hill = torch.max(pre_hill - percen, torch.zeros(pre_hill.size()).cuda())\n",
    "        np_hill = pre_hill.detach().cpu().numpy()\n",
    "        percen = np.percentile(np_hill, 75)\n",
    "        pre_hill /= percen\n",
    "        pre_hill = torch.clamp(pre_hill, 0, 1)\n",
    "        pre_hill = Avg_pool(pre_hill) \n",
    "        SIZE = int(im_size * im_size)\n",
    "        \n",
    "        loss_adv = CWLoss\n",
    "        \n",
    "        logist_B = target_model(real_A)\n",
    "        _, target = torch.max(logist_B, 1)\n",
    "        adv = real_A\n",
    "        ini_num = 1\n",
    "        grad_num = ini_num\n",
    "        mask = torch.zeros(1, 3, SIZE).cuda()\n",
    "\n",
    "        temp_eps = eps / 2\n",
    "\n",
    "        ##### Increasing\n",
    "        for iters in range(Iter):\n",
    "            # print (iters)\n",
    "            temp_A = Variable(adv.data, requires_grad=True)\n",
    "            logist_B = target_model(temp_A)\n",
    "            _, pre = torch.max(logist_B, 1)\n",
    "            \n",
    "            if target.cpu().data.float() != pre.cpu().data.float():\n",
    "                break\n",
    "            Loss = loss_adv(logist_B, target, -100, False) / real_A.size(0)\n",
    "            \n",
    "            target_model.zero_grad()\n",
    "            if temp_A.grad is not None:\n",
    "                temp_A.grad.data.fill_(0)\n",
    "            Loss.backward()\n",
    "            \n",
    "            grad = temp_A.grad\n",
    "            abs_grad = torch.abs(grad).view(1, 3, -1).mean(1, keepdim=True)\n",
    "            abs_grad = abs_grad * pre_hill\n",
    "            if not boost:\n",
    "                abs_grad = abs_grad * (1 - mask)\n",
    "            _, grad_sort_idx = torch.sort(abs_grad)\n",
    "            grad_sort_idx = grad_sort_idx.view(-1)\n",
    "            grad_idx = grad_sort_idx[-grad_num:]\n",
    "            mask[0, :, grad_idx] = 1.\n",
    "            temp_mask = mask.view(1, 3, im_size, im_size)\n",
    "            grad = temp_mask * grad\n",
    "            \n",
    "            abs_grad = torch.abs(grad)\n",
    "            abs_grad = abs_grad / torch.max(abs_grad)\n",
    "            normalized_grad = abs_grad * grad.sign()\n",
    "            scaled_grad = normalized_grad.mul(temp_eps)\n",
    "            temp_A = temp_A - scaled_grad\n",
    "            temp_A = clip(temp_A, real_A, eps)\n",
    "            adv = torch.clamp(temp_A, -1, 1)\n",
    "            if boost:\n",
    "                grad_num += ini_num\n",
    "            \n",
    "        final_adv = adv\n",
    "        adv_noise = real_A - final_adv\n",
    "        adv = final_adv\n",
    "        \n",
    "        abs_noise = torch.abs(adv_noise).view(1, 3, -1).mean(1, keepdim=True)\n",
    "        temp_mask = abs_noise != 0\n",
    "        modi_num = torch.sum(temp_mask).data.clone().item()\n",
    "        \n",
    "        reduce_num = modi_num\n",
    "        reduce_count = 0\n",
    "        ###### Reducing\n",
    "        if modi_num > 2:\n",
    "            reduce_idx = 0\n",
    "            while reduce_idx < reduce_num and reduce_count < 3000:\n",
    "                reduce_count += 1\n",
    "                adv_noise = real_A - adv\n",
    "                \n",
    "                abs_noise = torch.abs(adv_noise).view(1, 3, -1).mean(1, keepdim=True)\n",
    "                reduce_mask = abs_noise != 0\n",
    "                reduce_mask = reduce_mask.repeat(1, 3, 1).float()\n",
    "                abs_noise[abs_noise == 0] = 3.\n",
    "                \n",
    "                reduce_num = torch.sum(reduce_mask).data.clone().item() / 3\n",
    "                if reduce_num == 1:\n",
    "                    break\n",
    "                \n",
    "                noise_show, noise_sort_idx = torch.sort(abs_noise)\n",
    "                noise_sort_idx = noise_sort_idx.view( -1)\n",
    "                \n",
    "                noise_idx = noise_sort_idx[reduce_idx]\n",
    "                reduce_mask[0,:,noise_idx] = 0.\n",
    "                temp_mask = reduce_mask.view(1,3,int(im_size),int(im_size))\n",
    "                noise = temp_mask * adv_noise\n",
    "                \n",
    "                abs_noise = torch.abs(noise)\n",
    "                abs_noise = abs_noise / torch.max(abs_noise)\n",
    "                normalized_grad = abs_noise * noise.sign()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    target_model.eval()\n",
    "                    step = int(max(int(config.max_epsilon/10.),1))\n",
    "                    a = [i for i in range(0, int(config.max_epsilon+step), step)]\n",
    "                    search_num = len(a)\n",
    "                    a = np.asarray(a)*2/255. \n",
    "                    ex_temp_eps = torch.from_numpy(a).view(-1,1,1,1).float().cuda()\n",
    "                    ex_normalized_grad = normalized_grad.repeat(int(search_num),1,1,1)\n",
    "                    ex_scaled_grad = ex_normalized_grad.mul(ex_temp_eps)\n",
    "                    ex_real_A = real_A.repeat(int(search_num),1,1,1)\n",
    "                    ex_temp_A = ex_real_A - ex_scaled_grad\n",
    "                    ex_temp_A = clip(ex_temp_A, ex_real_A, eps)\n",
    "                    ex_adv = torch.clamp(ex_temp_A, -1, 1)\n",
    "                    ex_temp_A = Variable(ex_adv.data, requires_grad=False)\n",
    "                    ex_logist_B = target_model(ex_temp_A)\n",
    "                    _,pre=torch.max(ex_logist_B,1)\n",
    "                    comp = torch.eq(target.cpu().data.float(), pre.cpu().data.float())\n",
    "                    top1 = torch.sum(comp).float() / pre.size(0)\n",
    "                    if top1 != 1: ##### exists at least one adversarial sample\n",
    "                        found = False\n",
    "                        for i in range(int(search_num)):\n",
    "                            if comp[i] == 0:\n",
    "                                temp_adv = ex_temp_A[i:i+1]\n",
    "                                logist_B = target_model(temp_adv)\n",
    "                                _,pre=torch.max(logist_B,1)\n",
    "                                new_comp = torch.eq(target.cpu().data.float(), pre.cpu().data.float())\n",
    "                                if torch.sum(new_comp) != 0:\n",
    "                                    continue\n",
    "                                found = True\n",
    "                                adv = temp_adv\n",
    "                                break\n",
    "                        if found == False:\n",
    "                            reduce_idx += 1\n",
    "                    else:\n",
    "                        reduce_idx += 1\n",
    "                        \n",
    "        \n",
    "        adv_noise = real_A - adv\n",
    "        abs_noise = torch.abs(adv_noise).view(1, 3, -1).mean(1, keepdim=True)\n",
    "        temp_mask = abs_noise != 0\n",
    "        \n",
    "        reduce_num = torch.sum(temp_mask).data.clone().item()\n",
    "        L1_X_show = torch.max(torch.abs(real_A - adv)) * 255. / 2\n",
    "\n",
    "        num_count.append(reduce_num)\n",
    "\n",
    "        logist_B = target_model(adv)\n",
    "        _, pre = torch.max(logist_B, 1)\n",
    "        top1 = torch.sum(torch.eq(target.cpu().data.float(), pre.cpu().data.float()).float()) / input_A.size(0)\n",
    "\n",
    "        top1 = torch.from_numpy(np.asarray([(1 - top1)*100])).float().cuda()\n",
    "        Baccu[0].update(top1[0], input_A.size(0))\n",
    "        \n",
    "        print('[{it:.2f}][{name}] '\n",
    "                      'BTOP1: {BTOP1.avg:.2f} '\n",
    "                      'lossX: {ori:d}/{redu:d} '\n",
    "                      'L1: {l1:.1f} '\n",
    "                      'M&m {mean:.2f}/{median:.2f} '\n",
    "                      'Num: {num}'.format(\n",
    "                          it = float(idx*100)/len(test_loader),\n",
    "                          name = image_names[0].split('_')[-1],\n",
    "                          BTOP1 = Baccu[0],\n",
    "                          ori = int(modi_num),\n",
    "                          redu = int(reduce_num),\n",
    "                          l1 = L1_X_show.data.clone().item(),\n",
    "                          num = grad_num,\n",
    "                          mean = np.mean(num_count),\n",
    "                          median = np.median(num_count)))\n",
    "\n",
    "       \n",
    "        if not os.path.exists(root):\n",
    "            os.makedirs(root)\n",
    "        if not os.path.exists(os.path.join(root,'clean')):\n",
    "            os.makedirs(os.path.join(root,'clean'))\n",
    "        if not os.path.exists(os.path.join(root,'adv')):\n",
    "            os.makedirs(os.path.join(root,'adv'))\n",
    "        if not os.path.exists(os.path.join(root,'show')):\n",
    "            os.makedirs(os.path.join(root,'show'))\n",
    "\n",
    "        hill_imgs = pre_hill.view(pre_hill.size(0),1,im_size,im_size).repeat(1,3,1,1)\n",
    "        \n",
    "        if modi_num >= 0.:\n",
    "            for i in range(input_A.size(0)):\n",
    "                clip_img = ToPILImage()((adv[i].data.cpu()+ 1) / 2) \n",
    "                real_img = ToPILImage()((real_A[i].data.cpu()+ 1) / 2)\n",
    "                adv_path = os.path.join(root,'adv' ,image_names[i] +'_' +str(int(modi_num))+'.png')\n",
    "                clip_img.save(adv_path)\n",
    "                real_path = os.path.join(root,'clean', image_names[i] +'_' +str(int(modi_num))+'.png')\n",
    "                real_img.save(real_path)\n",
    "                \n",
    "                if True:\n",
    "                    hill_img = ToPILImage()(hill_imgs[i].data.cpu())\n",
    "                    temp_adv = torch.abs(adv_noise[i].data.cpu())\n",
    "                    temp_adv = temp_adv / torch.max(temp_adv)\n",
    "                    temp_adv = 1 - temp_adv\n",
    "                    adv_img = ToPILImage()(temp_adv)\n",
    "\n",
    "                    temp_hill = image_hill[i].data.cpu()\n",
    "                    \n",
    "                    temp_hill = 1 - temp_hill\n",
    "                    temp_hill = temp_hill.view(1,im_size,im_size).repeat(3,1,1)\n",
    "                    \n",
    "                    temp_hill = ToPILImage()(temp_hill)\n",
    "                    final = Image.fromarray(np.concatenate([temp_hill, hill_img, real_img,adv_img,clip_img],1))\n",
    "                    final.save( os.path.join(root,'show', image_names[i] +'_' +str(int(modi_num))+'.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Running test on ImageNet dataset, attacking model inception_v3.=====\n",
      "Iter 50\n",
      "EPS 100\n",
      "Boost:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00][00024227] BTOP1: 100.00 lossX: 112/86 L1: 100.0 M&m 86.00/86.00 T&t nan/nan Num: 16\n",
      "[0.10][00016067] BTOP1: 100.00 lossX: 61/36 L1: 100.0 M&m 61.00/61.00 T&t nan/nan Num: 12\n",
      "[0.20][00039584] BTOP1: 100.00 lossX: 374/171 L1: 100.0 M&m 97.67/86.00 T&t nan/nan Num: 30\n",
      "[0.30][00014296] BTOP1: 100.00 lossX: 48/22 L1: 100.0 M&m 78.75/61.00 T&t nan/nan Num: 11\n",
      "[0.40][00015954] BTOP1: 100.00 lossX: 318/169 L1: 100.0 M&m 96.80/86.00 T&t nan/nan Num: 29\n",
      "[0.50][00013030] BTOP1: 100.00 lossX: 21/10 L1: 100.0 M&m 82.33/61.00 T&t nan/nan Num: 7\n",
      "[0.60][00012589] BTOP1: 100.00 lossX: 133/53 L1: 100.0 M&m 78.14/53.00 T&t nan/nan Num: 18\n",
      "[0.70][00044718] BTOP1: 100.00 lossX: 3/1 L1: 60.0 M&m 68.50/44.50 T&t nan/nan Num: 3\n",
      "[0.80][00008843] BTOP1: 100.00 lossX: 297/215 L1: 100.0 M&m 84.78/53.00 T&t nan/nan Num: 29\n",
      "[0.90][00021404] BTOP1: 100.00 lossX: 473/156 L1: 100.0 M&m 91.90/69.50 T&t nan/nan Num: 37\n",
      "[1.00][00024608] BTOP1: 100.00 lossX: 35/24 L1: 100.0 M&m 85.73/53.00 T&t nan/nan Num: 9\n",
      "[1.10][00011416] BTOP1: 100.00 lossX: 3/1 L1: 30.0 M&m 78.67/44.50 T&t nan/nan Num: 3\n",
      "[1.20][00032541] BTOP1: 100.00 lossX: 431/277 L1: 100.0 M&m 93.92/53.00 T&t nan/nan Num: 34\n",
      "[1.30][00012037] BTOP1: 100.00 lossX: 138/90 L1: 100.0 M&m 93.64/69.50 T&t nan/nan Num: 18\n",
      "[1.40][00016403] BTOP1: 100.00 lossX: 368/234 L1: 100.0 M&m 103.00/86.00 T&t nan/nan Num: 35\n",
      "[1.50][00001751] BTOP1: 100.00 lossX: 92/83 L1: 100.0 M&m 101.75/84.50 T&t nan/nan Num: 15\n",
      "[1.60][00003273] BTOP1: 100.00 lossX: 204/149 L1: 100.0 M&m 104.53/86.00 T&t nan/nan Num: 26\n",
      "[1.70][00047575] BTOP1: 100.00 lossX: 52/32 L1: 100.0 M&m 100.50/84.50 T&t nan/nan Num: 12\n",
      "[1.80][00046613] BTOP1: 100.00 lossX: 101/66 L1: 100.0 M&m 98.68/83.00 T&t nan/nan Num: 16\n",
      "[1.90][00047340] BTOP1: 100.00 lossX: 5/3 L1: 90.0 M&m 93.90/74.50 T&t nan/nan Num: 4\n",
      "[2.00][00001416] BTOP1: 100.00 lossX: 13/5 L1: 90.0 M&m 89.67/66.00 T&t nan/nan Num: 6\n",
      "[2.10][00031299] BTOP1: 100.00 lossX: 44/23 L1: 100.0 M&m 86.64/59.50 T&t nan/nan Num: 11\n",
      "[2.20][00006945] BTOP1: 100.00 lossX: 266/137 L1: 100.0 M&m 88.83/66.00 T&t nan/nan Num: 32\n",
      "[2.30][00034437] BTOP1: 100.00 lossX: 64/38 L1: 100.0 M&m 86.71/59.50 T&t nan/nan Num: 14\n",
      "[2.40][00004590] BTOP1: 100.00 lossX: 28/27 L1: 100.0 M&m 84.32/53.00 T&t nan/nan Num: 8\n",
      "[2.50][00004188] BTOP1: 100.00 lossX: 6/2 L1: 80.0 M&m 81.15/45.50 T&t nan/nan Num: 4\n",
      "[2.60][00026456] BTOP1: 100.00 lossX: 51/15 L1: 100.0 M&m 78.70/38.00 T&t nan/nan Num: 11\n",
      "[2.70][00037644] BTOP1: 100.00 lossX: 15/9 L1: 100.0 M&m 76.21/37.00 T&t nan/nan Num: 6\n",
      "[2.80][00000353] BTOP1: 100.00 lossX: 21/14 L1: 94.0 M&m 74.07/36.00 T&t nan/nan Num: 7\n",
      "[2.90][00018048] BTOP1: 100.00 lossX: 186/69 L1: 90.0 M&m 73.90/37.00 T&t nan/nan Num: 22\n",
      "[3.00][00018932] BTOP1: 100.00 lossX: 308/198 L1: 100.0 M&m 77.90/38.00 T&t nan/nan Num: 29\n",
      "[3.10][00036735] BTOP1: 100.00 lossX: 1/1 L1: 50.0 M&m 75.50/37.00 T&t nan/nan Num: 2\n",
      "[3.20][00028980] BTOP1: 100.00 lossX: 49/17 L1: 100.0 M&m 73.73/36.00 T&t nan/nan Num: 11\n",
      "[3.30][00022871] BTOP1: 100.00 lossX: 1/1 L1: 50.0 M&m 71.59/34.00 T&t nan/nan Num: 2\n",
      "[3.40][00016700] BTOP1: 100.00 lossX: 6/4 L1: 100.0 M&m 69.66/32.00 T&t nan/nan Num: 4\n",
      "[3.50][00042957] BTOP1: 100.00 lossX: 85/40 L1: 100.0 M&m 68.83/34.00 T&t nan/nan Num: 14\n",
      "[3.60][00000207] BTOP1: 100.00 lossX: 3/2 L1: 60.0 M&m 67.03/32.00 T&t nan/nan Num: 3\n",
      "[3.70][00039717] BTOP1: 100.00 lossX: 48/28 L1: 100.0 M&m 66.00/30.00 T&t nan/nan Num: 11\n",
      "[3.80][00019442] BTOP1: 100.00 lossX: 26/11 L1: 100.0 M&m 64.59/28.00 T&t nan/nan Num: 8\n",
      "[3.90][00011210] BTOP1: 100.00 lossX: 17/16 L1: 100.0 M&m 63.38/27.50 T&t nan/nan Num: 7\n",
      "[4.00][00026139] BTOP1: 100.00 lossX: 121/76 L1: 100.0 M&m 63.68/28.00 T&t nan/nan Num: 19\n",
      "[4.10][00036190] BTOP1: 100.00 lossX: 3/2 L1: 70.0 M&m 62.21/27.50 T&t nan/nan Num: 3\n",
      "[4.20][00043855] BTOP1: 100.00 lossX: 61/27 L1: 100.0 M&m 61.40/27.00 T&t nan/nan Num: 12\n",
      "[4.30][00003688] BTOP1: 100.00 lossX: 11/6 L1: 100.0 M&m 60.14/27.00 T&t nan/nan Num: 6\n",
      "[4.40][00000145] BTOP1: 97.78 lossX: 781/781 L1: 100.0 M&m 76.16/27.00 T&t nan/nan Num: 51\n",
      "[4.50][00007218] BTOP1: 97.83 lossX: 8/5 L1: 90.0 M&m 74.61/27.00 T&t nan/nan Num: 5\n",
      "[4.60][00026676] BTOP1: 97.87 lossX: 294/185 L1: 100.0 M&m 76.96/27.00 T&t nan/nan Num: 26\n",
      "[4.70][00016029] BTOP1: 97.92 lossX: 89/70 L1: 100.0 M&m 76.81/27.50 T&t nan/nan Num: 15\n",
      "[4.80][00019756] BTOP1: 97.96 lossX: 62/44 L1: 100.0 M&m 76.14/28.00 T&t nan/nan Num: 14\n",
      "[4.90][00031966] BTOP1: 98.00 lossX: 460/290 L1: 100.0 M&m 80.42/30.00 T&t nan/nan Num: 37\n",
      "[5.00][00026933] BTOP1: 98.04 lossX: 553/333 L1: 100.0 M&m 85.37/32.00 T&t nan/nan Num: 41\n",
      "[5.10][00049966] BTOP1: 98.08 lossX: 519/276 L1: 100.0 M&m 89.04/34.00 T&t nan/nan Num: 36\n",
      "[5.20][00004093] BTOP1: 98.11 lossX: 128/92 L1: 100.0 M&m 89.09/36.00 T&t nan/nan Num: 18\n",
      "[5.30][00002912] BTOP1: 98.15 lossX: 142/77 L1: 100.0 M&m 88.87/37.00 T&t nan/nan Num: 22\n",
      "[5.40][00000547] BTOP1: 98.18 lossX: 184/136 L1: 100.0 M&m 89.73/38.00 T&t nan/nan Num: 22\n",
      "[5.50][00016551] BTOP1: 98.21 lossX: 93/65 L1: 100.0 M&m 89.29/39.00 T&t nan/nan Num: 16\n",
      "[5.60][00037474] BTOP1: 98.25 lossX: 613/222 L1: 100.0 M&m 91.61/40.00 T&t nan/nan Num: 40\n",
      "[5.70][00048382] BTOP1: 98.28 lossX: 3/2 L1: 90.0 M&m 90.07/39.00 T&t nan/nan Num: 4\n",
      "[5.80][00030046] BTOP1: 98.31 lossX: 33/24 L1: 100.0 M&m 88.95/38.00 T&t nan/nan Num: 9\n",
      "[5.90][00013072] BTOP1: 98.33 lossX: 6/4 L1: 84.0 M&m 87.53/37.00 T&t nan/nan Num: 4\n",
      "[6.00][00040074] BTOP1: 98.36 lossX: 79/47 L1: 100.0 M&m 86.87/38.00 T&t nan/nan Num: 14\n",
      "[6.10][00037414] BTOP1: 98.39 lossX: 367/249 L1: 100.0 M&m 89.48/39.00 T&t nan/nan Num: 31\n",
      "[6.20][00003427] BTOP1: 98.41 lossX: 14/11 L1: 100.0 M&m 88.24/38.00 T&t nan/nan Num: 6\n",
      "[6.30][00033984] BTOP1: 98.44 lossX: 51/33 L1: 100.0 M&m 87.38/37.00 T&t nan/nan Num: 11\n",
      "[6.40][00029867] BTOP1: 96.92 lossX: 872/872 L1: 100.0 M&m 99.45/38.00 T&t nan/nan Num: 51\n",
      "[6.50][00046155] BTOP1: 96.97 lossX: 9/4 L1: 90.0 M&m 98.00/37.00 T&t nan/nan Num: 5\n",
      "[6.60][00025498] BTOP1: 97.01 lossX: 151/110 L1: 100.0 M&m 98.18/38.00 T&t nan/nan Num: 22\n",
      "[6.70][00003484] BTOP1: 97.06 lossX: 3/2 L1: 47.4 M&m 96.76/37.00 T&t nan/nan Num: 3\n",
      "[6.80][00028754] BTOP1: 97.10 lossX: 75/57 L1: 100.0 M&m 96.19/38.00 T&t nan/nan Num: 14\n",
      "[6.90][00012398] BTOP1: 97.14 lossX: 397/226 L1: 100.0 M&m 98.04/39.00 T&t nan/nan Num: 31\n",
      "[7.00][00047982] BTOP1: 97.18 lossX: 94/73 L1: 100.0 M&m 97.69/40.00 T&t nan/nan Num: 15\n",
      "[7.10][00010154] BTOP1: 97.22 lossX: 113/101 L1: 100.0 M&m 97.74/42.00 T&t nan/nan Num: 17\n",
      "[7.20][00034350] BTOP1: 97.26 lossX: 125/101 L1: 100.0 M&m 97.78/44.00 T&t nan/nan Num: 17\n",
      "[7.30][00043594] BTOP1: 97.30 lossX: 116/72 L1: 100.0 M&m 97.43/45.50 T&t nan/nan Num: 17\n",
      "[7.40][00020445] BTOP1: 97.33 lossX: 20/15 L1: 100.0 M&m 96.33/44.00 T&t nan/nan Num: 7\n",
      "[7.50][00022834] BTOP1: 97.37 lossX: 382/266 L1: 100.0 M&m 98.57/45.50 T&t nan/nan Num: 33\n",
      "[7.60][00039201] BTOP1: 97.40 lossX: 75/56 L1: 100.0 M&m 98.01/47.00 T&t nan/nan Num: 13\n",
      "[7.70][00009697] BTOP1: 97.44 lossX: 112/86 L1: 100.0 M&m 97.86/50.00 T&t nan/nan Num: 16\n",
      "[7.80][00006563] BTOP1: 96.20 lossX: 591/591 L1: 100.0 M&m 104.10/53.00 T&t nan/nan Num: 51\n",
      "[7.90][00043472] BTOP1: 96.25 lossX: 301/106 L1: 100.0 M&m 104.12/54.50 T&t nan/nan Num: 28\n",
      "[8.00][00031923] BTOP1: 96.30 lossX: 13/11 L1: 100.0 M&m 102.98/53.00 T&t nan/nan Num: 6\n",
      "[8.10][00018055] BTOP1: 96.34 lossX: 1/1 L1: 50.0 M&m 101.73/50.00 T&t nan/nan Num: 2\n",
      "[8.20][00006000] BTOP1: 96.39 lossX: 18/8 L1: 100.0 M&m 100.60/47.00 T&t nan/nan Num: 7\n",
      "[8.30][00019631] BTOP1: 96.43 lossX: 120/52 L1: 100.0 M&m 100.02/49.50 T&t nan/nan Num: 19\n",
      "[8.40][00027343] BTOP1: 95.29 lossX: 890/890 L1: 100.0 M&m 109.32/52.00 T&t nan/nan Num: 51\n",
      "[8.50][00002357] BTOP1: 95.35 lossX: 247/175 L1: 100.0 M&m 110.08/52.50 T&t nan/nan Num: 38\n",
      "[8.60][00044719] BTOP1: 95.40 lossX: 39/25 L1: 100.0 M&m 109.10/52.00 T&t nan/nan Num: 10\n",
      "[8.70][00004538] BTOP1: 95.45 lossX: 20/11 L1: 100.0 M&m 107.99/49.50 T&t nan/nan Num: 7\n",
      "[8.80][00041001] BTOP1: 95.51 lossX: 1/1 L1: 50.0 M&m 106.79/47.00 T&t nan/nan Num: 2\n",
      "[8.90][00038471] BTOP1: 95.56 lossX: 10/3 L1: 100.0 M&m 105.63/45.50 T&t nan/nan Num: 5\n",
      "[9.00][00022528] BTOP1: 95.60 lossX: 44/16 L1: 100.0 M&m 104.65/44.00 T&t nan/nan Num: 10\n",
      "[9.10][00046785] BTOP1: 95.65 lossX: 93/47 L1: 100.0 M&m 104.02/45.50 T&t nan/nan Num: 15\n",
      "[9.20][00004300] BTOP1: 95.70 lossX: 6/5 L1: 63.0 M&m 102.96/44.00 T&t nan/nan Num: 4\n",
      "[9.30][00048937] BTOP1: 95.74 lossX: 20/14 L1: 100.0 M&m 102.01/42.00 T&t nan/nan Num: 7\n",
      "[9.40][00006302] BTOP1: 95.79 lossX: 44/24 L1: 100.0 M&m 101.19/40.00 T&t nan/nan Num: 10\n",
      "[9.50][00002107] BTOP1: 95.83 lossX: 13/4 L1: 100.0 M&m 100.18/39.00 T&t nan/nan Num: 6\n",
      "[9.60][00032939] BTOP1: 95.88 lossX: 85/26 L1: 100.0 M&m 99.41/38.00 T&t nan/nan Num: 16\n",
      "[9.70][00019953] BTOP1: 95.92 lossX: 1/1 L1: 35.8 M&m 98.41/37.00 T&t nan/nan Num: 2\n",
      "[9.80][00019723] BTOP1: 95.96 lossX: 10/6 L1: 81.0 M&m 97.47/36.00 T&t nan/nan Num: 5\n",
      "[9.90][00048720] BTOP1: 96.00 lossX: 126/102 L1: 100.0 M&m 97.52/37.00 T&t nan/nan Num: 19\n",
      "[10.00][00045133] BTOP1: 96.04 lossX: 234/120 L1: 100.0 M&m 97.74/38.00 T&t nan/nan Num: 25\n",
      "[10.10][00038622] BTOP1: 96.08 lossX: 34/23 L1: 100.0 M&m 97.01/37.00 T&t nan/nan Num: 11\n",
      "[10.20][00004250] BTOP1: 96.12 lossX: 84/61 L1: 100.0 M&m 96.66/38.00 T&t nan/nan Num: 14\n",
      "[10.30][00026591] BTOP1: 96.15 lossX: 149/91 L1: 100.0 M&m 96.61/39.00 T&t nan/nan Num: 20\n",
      "[10.40][00049097] BTOP1: 96.19 lossX: 43/24 L1: 100.0 M&m 95.91/38.00 T&t nan/nan Num: 10\n",
      "[10.50][00025935] BTOP1: 96.23 lossX: 24/7 L1: 100.0 M&m 95.08/37.00 T&t nan/nan Num: 9\n",
      "[10.60][00045109] BTOP1: 96.26 lossX: 3/2 L1: 40.0 M&m 94.21/36.00 T&t nan/nan Num: 3\n",
      "[10.70][00036620] BTOP1: 96.30 lossX: 100/63 L1: 100.0 M&m 93.92/37.00 T&t nan/nan Num: 16\n",
      "[10.80][00001747] BTOP1: 96.33 lossX: 6/3 L1: 90.0 M&m 93.08/36.00 T&t nan/nan Num: 4\n",
      "[10.90][00019529] BTOP1: 96.36 lossX: 9/3 L1: 100.0 M&m 92.26/34.50 T&t nan/nan Num: 5\n",
      "[11.00][00048847] BTOP1: 96.40 lossX: 80/24 L1: 100.0 M&m 91.65/33.00 T&t nan/nan Num: 14\n",
      "[11.10][00047098] BTOP1: 96.43 lossX: 85/70 L1: 100.0 M&m 91.46/34.50 T&t nan/nan Num: 15\n",
      "[11.20][00031024] BTOP1: 96.46 lossX: 59/47 L1: 100.0 M&m 91.06/36.00 T&t nan/nan Num: 12\n",
      "[11.30][00032558] BTOP1: 96.49 lossX: 6/3 L1: 100.0 M&m 90.29/34.50 T&t nan/nan Num: 4\n",
      "[11.40][00040568] BTOP1: 96.52 lossX: 3/2 L1: 60.0 M&m 89.52/33.00 T&t nan/nan Num: 3\n",
      "[11.50][00036123] BTOP1: 96.55 lossX: 130/95 L1: 100.0 M&m 89.57/34.50 T&t nan/nan Num: 25\n",
      "[11.60][00000640] BTOP1: 96.58 lossX: 84/31 L1: 100.0 M&m 89.07/33.00 T&t nan/nan Num: 16\n",
      "[11.70][00041868] BTOP1: 96.61 lossX: 51/30 L1: 100.0 M&m 88.57/32.50 T&t nan/nan Num: 11\n",
      "[11.80][00014049] BTOP1: 96.64 lossX: 14/9 L1: 97.0 M&m 87.90/32.00 T&t nan/nan Num: 6\n",
      "[11.90][00023788] BTOP1: 96.67 lossX: 37/25 L1: 100.0 M&m 87.38/31.50 T&t nan/nan Num: 10\n",
      "[12.00][00037092] BTOP1: 96.69 lossX: 13/7 L1: 90.0 M&m 86.71/31.00 T&t nan/nan Num: 6\n",
      "[12.10][00045615] BTOP1: 96.72 lossX: 9/8 L1: 63.0 M&m 86.07/30.50 T&t nan/nan Num: 5\n",
      "[12.20][00020196] BTOP1: 96.75 lossX: 14/9 L1: 100.0 M&m 85.44/30.00 T&t nan/nan Num: 6\n",
      "[12.30][00035671] BTOP1: 96.77 lossX: 113/65 L1: 100.0 M&m 85.27/30.50 T&t nan/nan Num: 16\n",
      "[12.40][00046394] BTOP1: 96.80 lossX: 103/68 L1: 100.0 M&m 85.14/31.00 T&t nan/nan Num: 16\n",
      "[12.50][00024417] BTOP1: 96.83 lossX: 62/44 L1: 100.0 M&m 84.81/31.50 T&t nan/nan Num: 13\n",
      "[12.60][00001230] BTOP1: 96.85 lossX: 107/66 L1: 100.0 M&m 84.66/32.00 T&t nan/nan Num: 18\n",
      "[12.70][00000617] BTOP1: 96.88 lossX: 34/21 L1: 100.0 M&m 84.16/31.50 T&t nan/nan Num: 9\n",
      "[12.80][00041705] BTOP1: 96.90 lossX: 60/14 L1: 100.0 M&m 83.62/31.00 T&t nan/nan Num: 12\n",
      "[12.90][00048437] BTOP1: 96.92 lossX: 83/54 L1: 100.0 M&m 83.39/31.50 T&t nan/nan Num: 14\n",
      "[13.00][00028799] BTOP1: 96.95 lossX: 21/16 L1: 96.6 M&m 82.88/31.00 T&t nan/nan Num: 7\n",
      "[13.10][00044116] BTOP1: 96.97 lossX: 23/15 L1: 100.0 M&m 82.36/30.50 T&t nan/nan Num: 8\n",
      "[13.20][00048630] BTOP1: 96.99 lossX: 241/169 L1: 100.0 M&m 83.02/31.00 T&t nan/nan Num: 24\n",
      "[13.30][00035080] BTOP1: 97.01 lossX: 586/357 L1: 100.0 M&m 85.06/31.50 T&t nan/nan Num: 42\n",
      "[13.40][00012662] BTOP1: 97.04 lossX: 383/229 L1: 100.0 M&m 86.13/32.00 T&t nan/nan Num: 44\n",
      "[13.50][00027968] BTOP1: 97.06 lossX: 690/237 L1: 100.0 M&m 87.24/32.50 T&t nan/nan Num: 41\n",
      "[13.60][00037163] BTOP1: 97.08 lossX: 231/140 L1: 100.0 M&m 87.62/33.00 T&t nan/nan Num: 25\n",
      "[13.70][00024024] BTOP1: 97.10 lossX: 183/99 L1: 100.0 M&m 87.70/34.50 T&t nan/nan Num: 22\n",
      "[13.80][00044897] BTOP1: 97.12 lossX: 87/58 L1: 100.0 M&m 87.49/36.00 T&t nan/nan Num: 14\n",
      "[13.90][00028681] BTOP1: 97.14 lossX: 10/8 L1: 66.7 M&m 86.92/34.50 T&t nan/nan Num: 5\n",
      "[14.00][00025625] BTOP1: 97.16 lossX: 579/251 L1: 100.0 M&m 88.09/36.00 T&t nan/nan Num: 39\n",
      "[14.10][00005421] BTOP1: 97.18 lossX: 31/11 L1: 80.0 M&m 87.54/34.50 T&t nan/nan Num: 9\n",
      "[14.20][00002906] BTOP1: 97.20 lossX: 182/100 L1: 100.0 M&m 87.63/36.00 T&t nan/nan Num: 25\n",
      "[14.30][00036351] BTOP1: 97.22 lossX: 204/107 L1: 100.0 M&m 87.76/37.00 T&t nan/nan Num: 25\n",
      "[14.40][00042277] BTOP1: 97.24 lossX: 59/42 L1: 100.0 M&m 87.45/38.00 T&t nan/nan Num: 13\n",
      "[14.50][00022484] BTOP1: 97.26 lossX: 249/160 L1: 100.0 M&m 87.95/39.00 T&t nan/nan Num: 26\n",
      "[14.60][00021705] BTOP1: 97.28 lossX: 153/73 L1: 100.0 M&m 87.84/40.00 T&t nan/nan Num: 23\n",
      "[14.70][00014699] BTOP1: 97.30 lossX: 9/8 L1: 100.0 M&m 87.30/39.00 T&t nan/nan Num: 5\n",
      "[14.80][00001282] BTOP1: 97.32 lossX: 53/20 L1: 100.0 M&m 86.85/38.00 T&t nan/nan Num: 12\n",
      "[14.90][00005178] BTOP1: 97.33 lossX: 68/49 L1: 100.0 M&m 86.60/39.00 T&t nan/nan Num: 13\n",
      "[15.00][00004583] BTOP1: 97.35 lossX: 49/27 L1: 100.0 M&m 86.21/38.00 T&t nan/nan Num: 12\n",
      "[15.10][00041575] BTOP1: 97.37 lossX: 67/20 L1: 100.0 M&m 85.77/37.00 T&t nan/nan Num: 14\n",
      "[15.20][00037183] BTOP1: 97.39 lossX: 1/1 L1: 50.0 M&m 85.22/36.00 T&t nan/nan Num: 2\n",
      "[15.30][00012687] BTOP1: 97.40 lossX: 3/1 L1: 90.0 M&m 84.67/34.50 T&t nan/nan Num: 3\n",
      "[15.40][00034606] BTOP1: 97.42 lossX: 116/98 L1: 100.0 M&m 84.75/36.00 T&t nan/nan Num: 17\n",
      "[15.50][00021763] BTOP1: 97.44 lossX: 227/153 L1: 100.0 M&m 85.19/37.00 T&t nan/nan Num: 25\n",
      "[15.60][00012341] BTOP1: 97.45 lossX: 1/1 L1: 50.0 M&m 84.66/36.00 T&t nan/nan Num: 2\n",
      "[15.70][00042687] BTOP1: 97.47 lossX: 151/81 L1: 100.0 M&m 84.63/37.00 T&t nan/nan Num: 19\n",
      "[15.80][00012190] BTOP1: 97.48 lossX: 508/356 L1: 100.0 M&m 86.34/38.00 T&t nan/nan Num: 38\n",
      "[15.90][00017412] BTOP1: 97.50 lossX: 5/3 L1: 80.0 M&m 85.82/37.00 T&t nan/nan Num: 4\n",
      "[16.00][00032427] BTOP1: 97.52 lossX: 15/6 L1: 100.0 M&m 85.32/36.00 T&t nan/nan Num: 6\n",
      "[16.10][00014828] BTOP1: 97.53 lossX: 142/114 L1: 100.0 M&m 85.50/37.00 T&t nan/nan Num: 20\n",
      "[16.20][00039730] BTOP1: 97.55 lossX: 254/152 L1: 100.0 M&m 85.91/38.00 T&t nan/nan Num: 28\n",
      "[16.30][00022571] BTOP1: 97.56 lossX: 47/43 L1: 100.0 M&m 85.65/39.00 T&t nan/nan Num: 11\n",
      "[16.40][00010565] BTOP1: 97.58 lossX: 162/105 L1: 100.0 M&m 85.76/40.00 T&t nan/nan Num: 21\n",
      "[16.50][00046758] BTOP1: 97.59 lossX: 1/1 L1: 50.0 M&m 85.25/39.00 T&t nan/nan Num: 2\n",
      "[16.60][00035258] BTOP1: 97.60 lossX: 53/26 L1: 100.0 M&m 84.90/38.00 T&t nan/nan Num: 12\n",
      "[16.70][00023194] BTOP1: 97.62 lossX: 18/11 L1: 100.0 M&m 84.46/37.00 T&t nan/nan Num: 7\n",
      "[16.80][00003222] BTOP1: 97.63 lossX: 319/250 L1: 100.0 M&m 85.44/38.00 T&t nan/nan Num: 32\n",
      "[16.90][00006695] BTOP1: 97.65 lossX: 150/76 L1: 100.0 M&m 85.38/39.00 T&t nan/nan Num: 20\n",
      "[17.00][00045368] BTOP1: 97.66 lossX: 8/2 L1: 90.0 M&m 84.89/38.00 T&t nan/nan Num: 5\n",
      "[17.10][00034380] BTOP1: 97.67 lossX: 71/42 L1: 100.0 M&m 84.65/39.00 T&t nan/nan Num: 13\n",
      "[17.20][00017593] BTOP1: 97.69 lossX: 74/59 L1: 100.0 M&m 84.50/40.00 T&t nan/nan Num: 13\n",
      "[17.30][00026902] BTOP1: 97.70 lossX: 158/96 L1: 100.0 M&m 84.56/41.00 T&t nan/nan Num: 20\n",
      "[17.40][00010782] BTOP1: 97.71 lossX: 72/47 L1: 100.0 M&m 84.35/42.00 T&t nan/nan Num: 13\n",
      "[17.50][00029113] BTOP1: 97.73 lossX: 21/14 L1: 100.0 M&m 83.95/41.00 T&t nan/nan Num: 7\n",
      "[17.60][00033229] BTOP1: 97.74 lossX: 100/58 L1: 100.0 M&m 83.80/42.00 T&t nan/nan Num: 16\n",
      "[17.70][00012837] BTOP1: 97.75 lossX: 299/137 L1: 100.0 M&m 84.10/42.00 T&t nan/nan Num: 30\n",
      "[17.80][00036188] BTOP1: 97.77 lossX: 2/2 L1: 100.0 M&m 83.64/42.00 T&t nan/nan Num: 3\n",
      "[17.90][00042917] BTOP1: 97.78 lossX: 22/8 L1: 50.0 M&m 83.22/41.00 T&t nan/nan Num: 8\n",
      "[18.00][00046687] BTOP1: 97.79 lossX: 36/22 L1: 90.0 M&m 82.88/40.00 T&t nan/nan Num: 9\n",
      "[18.10][00047346] BTOP1: 97.25 lossX: 767/767 L1: 100.0 M&m 86.64/41.00 T&t nan/nan Num: 51\n",
      "[18.20][00012800] BTOP1: 97.27 lossX: 475/225 L1: 100.0 M&m 87.40/42.00 T&t nan/nan Num: 38\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6b3fc3e3fdf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mattack_algorithm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'greedyfool_w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mtest_attack_success_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack_algorithm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-f5e7c997782f>\u001b[0m in \u001b[0;36mtest_attack_success_rate\u001b[0;34m(config, target_model, attack_algorithm, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Untargeted'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ImageNet'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# untargeted attack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-37d490c14ea7>\u001b[0m in \u001b[0;36mgreedyfool_attack_white\u001b[0;34m(target_model, test_loader, config, generator)\u001b[0m\n\u001b[1;32m    180\u001b[0m                     \u001b[0mex_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex_temp_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                     \u001b[0mex_temp_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex_adv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                     \u001b[0mex_logist_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex_temp_A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex_logist_B\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                     \u001b[0mcomp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Experiment/models/inception_v3_imagenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# 35 x 35 x 192\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMixed_5b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;31m# 35 x 35 x 256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMixed_5c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Experiment/models/inception_v3_imagenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mbranch_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mbranch_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbranch_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbranch_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbranch1x1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch5x5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch3x3dbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch_pool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Experiment/models/inception_v3_imagenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "\n",
    "##### Target model loading\n",
    "#netT = models.inception_v3(pretrained=True)\n",
    "netT = inception_v3.inception_v3(pretrained=False)\n",
    "netT.load_state_dict(torch.load('./checkpoints/inception_v3.pth'))\n",
    "netT.eval()\n",
    "netT.cuda()\n",
    "\n",
    "##### Generator loading for distortion map\n",
    "netG = generators.Res_ResnetGenerator(3, 1, 16, norm_type='batch', act_type='relu')\n",
    "netG = torch.nn.DataParallel(netG, device_ids=range(torch.cuda.device_count()))\n",
    "netG.load_state_dict(torch.load('./checkpoints/G_imagenet.pth'))\n",
    "netG.cuda()\n",
    "netG.eval()\n",
    "\n",
    "\n",
    "config = Namespace()\n",
    "config.root = '.result/'\n",
    "config.target_type = 'Untargeted'\n",
    "config.dataset_type = 'ImageNet'\n",
    "config.target_model = 'inception_v3'\n",
    "config.iter = 50\n",
    "config.max_epsilon = 100\n",
    "config.image_size = 299\n",
    "config.saving_root = './result/Greedyfool/untargeted/'\n",
    "\n",
    "attack_algorithm = attack_factory('greedyfool_w')\n",
    "\n",
    "test_attack_success_rate(config, netT, attack_algorithm, generator=netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
