{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from utils.imagenet_dataset import ImageNetDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToPILImage\n",
    "import models.inception_v3_imagenet as inception_v3\n",
    "import models.generators as generators\n",
    "import models.resnet_cifar10 as resnet\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model_path='./checkpoints', no_cuda='False', seed=5, target_count=20, target_label=-1, target_type=0, test_batch_size=50)\n"
     ]
    }
   ],
   "source": [
    "sys.argv = ['uniform_testing.ipynb', \n",
    "            '--no-cuda', 'False',\n",
    "            '--seed', '5', \n",
    "            '--model-path', './checkpoints',\n",
    "            '--test-batch-size', '50',\n",
    "            '--target-count', '20',\n",
    "            '--target-type', '0',\n",
    "            '--target-label', '-1'\n",
    "            ]\n",
    "parser = argparse.ArgumentParser(description='Black-box Adversarial Attack')\n",
    "parser.add_argument('--no-cuda', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=0, metavar='S',\n",
    "                    help='random seed (default: 0)')\n",
    "parser.add_argument('--model-path', default='../../checkpoints',\n",
    "                    help='directory of model for saving checkpoint')\n",
    "parser.add_argument('--test-batch-size', type=int, default=50, metavar='N',\n",
    "                    help='input batch size for testing (default: 50)')\n",
    "parser.add_argument('--target-count', type=int, default=20, metavar='N',\n",
    "                    help='the amount of targets(default: 20)')\n",
    "parser.add_argument('--target-type', type=int, default=0, metavar='N',\n",
    "                    help='the method of choosing target label.\\n0: ini_label + 1;\\n1: all the other labels')\n",
    "parser.add_argument('--target-label', type=int, default=-1, metavar='N',\n",
    "                    help='target label, default: -1, which is (ini_label + 1) % 10')\n",
    "args = parser.parse_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify optimization related parameters\n",
    "LR = 0.05  # learning rate\n",
    "EPOCHS = 20  # total optimization epochs\n",
    "NB_SAMPLE = 1000  # number of samples for adjusting lambda\n",
    "MINI_BATCH = NB_SAMPLE // args.test_batch_size  # number of batches\n",
    "INIT_COST = 1e-3  # initial weight of lambda\n",
    "\n",
    "ATTACK_SUCC_THRESHOLD = 0.99  # attack success threshold\n",
    "PATIENCE = 5  # patience for adjusting lambda, number of mini batches\n",
    "COST_MULTIPLIER = 2  # multiplier for auto-control of weight (COST)\n",
    "COST_MULTIPLIER_UP = COST_MULTIPLIER\n",
    "COST_MULTIPLIER_DOWN = 10 ** 0.5  # changed from 2**1.5 to 10**0.5\n",
    "\n",
    "EARLY_STOP_THRESHOLD = 1.0  # loss threshold for early stop\n",
    "EARLY_STOP_PATIENCE = 5 * PATIENCE  # patience for early stop\n",
    "EPSILON = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_factory(dataset_type = 'ImageNet', no_cuda = False, batch_size = 1):\n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "    if dataset_type == 'Cifar10':\n",
    "        kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "        dataset = torchvision.datasets.CIFAR10(\n",
    "            root='./datasets', train=False, download=True, \n",
    "            transform=transforms.Compose([\n",
    "                transforms.CenterCrop(31),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "        )\n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "    elif dataset_type == 'ImageNet':\n",
    "        im_size = 299\n",
    "        mean_arr = (0.5, 0.5, 0.5)\n",
    "        stddev_arr = (0.5, 0.5, 0.5)\n",
    "        dataset = ImageNetDataset(\n",
    "            image_dir='./datasets/imagenet1000',\n",
    "            label_filepath=\"./datasets/imagenet_label.txt\",\n",
    "            transform=transforms.Compose([\n",
    "                transforms.CenterCrop(im_size),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean_arr, stddev_arr)\n",
    "            ]),\n",
    "        )\n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    " \n",
    "\n",
    "def test_attack_success_rate(config, target_model, attack_algorithm, **kwargs):\n",
    "    # sourcery skip: last-if-guard, use-fstring-for-concatenation\n",
    "    \"\"\"This is the unified model for testing attack success rate for adversarial success under a certain configuration.\n",
    "\n",
    "    Args:\n",
    "        config (Namespace): include the attack type(black or white, targeted or untargeted) and other necessary information\n",
    "        target_model: the model to be attacked\n",
    "        data_loader: batch_size = 1\n",
    "    \"\"\"\n",
    "    print(f\"=====Running test on {config.dataset_type} dataset, attacking model {config.target_model}.=====\")\n",
    "    dataloader = data_factory(config.dataset_type)\n",
    "    if config.target_type == 'Untargeted':\n",
    "        result = attack_algorithm(target_model, dataloader, config, **kwargs)  # untargeted attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_factory(attack_algorithm):\n",
    "    mapping = {'B3D_w': B3D_attack_black,\n",
    "               'greedyfool_w': greedyfool_attack_white, \n",
    "               'cornersearch_w': cornersearch_attack_black, \n",
    "               'PGD_attack_w': PGD_attack_white, \n",
    "               'homotopy_w': homotopy_attack_white, \n",
    "               'perturbation_w': perturbation_attack_black}\n",
    "    return mapping[attack_algorithm]\n",
    "\n",
    "def greedyfool_attack_white():\n",
    "    pass\n",
    "\n",
    "def greedyfool_attack_black():\n",
    "    pass\n",
    "\n",
    "def B3D_attack_black():\n",
    "    pass\n",
    "\n",
    "def cornersearch_attack_black():\n",
    "    pass\n",
    "\n",
    "def PGD_attack_white():\n",
    "    pass\n",
    "\n",
    "def homotopy_attack_white():\n",
    "    pass\n",
    "\n",
    "def perturbation_attack_black():\n",
    "    pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedyfool_attack_white(target_model, test_loader, config, generator):\n",
    "    def clip(adv_A,real_A,eps):\n",
    "        g_x=real_A-adv_A\n",
    "        clip_gx=torch.clamp(g_x, min=-eps, max=eps)\n",
    "        adv_x=real_A-clip_gx\n",
    "        return adv_x\n",
    "    \n",
    "    def CWLoss(logits, target, kappa=0, tar=True if config.target_type == 'Targeted' else False):\n",
    "        if config.dataset_type == 'ImageNet':\n",
    "            target = torch.ones(logits.size(0)).type(torch.cuda.FloatTensor).mul(target.float())\n",
    "            target_one_hot = Variable(torch.eye(1000).type(torch.cuda.FloatTensor)[target.long()].cuda())\n",
    "            \n",
    "            real = torch.sum(target_one_hot*logits, 1)\n",
    "            other = torch.max((1-target_one_hot)*logits - (target_one_hot*10000), 1)[0]\n",
    "            kappa = torch.zeros_like(other).fill_(kappa)\n",
    "        elif config.dataset_type == 'Cifar10':\n",
    "            target = torch.ones(logits.size(0)).type(torch.cuda.FloatTensor).mul(target.float())\n",
    "            target_one_hot = Variable(torch.eye(10).type(torch.cuda.FloatTensor)[target.long()].cuda())\n",
    "            \n",
    "            real = torch.sum(target_one_hot*logits, 1)\n",
    "            other = torch.max((1-target_one_hot)*logits - (target_one_hot*10000), 1)[0]  ## 这里的10000是什么原理\n",
    "            kappa = torch.zeros_like(other).fill_(kappa)\n",
    "        \n",
    "        if tar:\n",
    "            return torch.sum(torch.max(other - real, kappa))\n",
    "        else:\n",
    "            return torch.sum(torch.max(real - other, kappa))\n",
    "    \n",
    "    class AverageMeter(object):\n",
    "        \"\"\"Computes and stores the average and current value\"\"\"\n",
    "        def __init__(self):\n",
    "            self.reset()\n",
    "\n",
    "        def reset(self):\n",
    "            self.val = 0\n",
    "            self.avg = 0\n",
    "            self.sum = 0\n",
    "            self.count = 0\n",
    "\n",
    "        def update(self, val, n=1):\n",
    "            self.val = val\n",
    "            self.sum += val * n\n",
    "            self.count += n\n",
    "            self.avg = self.sum / self.count\n",
    "    \n",
    "    pool_kernel = 3\n",
    "    Avg_pool = nn.AvgPool2d(pool_kernel, stride=1, padding=int(pool_kernel/2))\n",
    "    \n",
    "    print(\"Iter {0}\".format(config.iter))\n",
    "    print(\"EPS {0}\".format(config.max_epsilon))\n",
    "    Iter = config.iter\n",
    "    eps = config.max_epsilon * 2 / 255\n",
    "    im_size = config.image_size\n",
    "    root = config.saving_root\n",
    "    \n",
    "    Baccu = []\n",
    "    for i in range(1):\n",
    "        temp_accu = AverageMeter()\n",
    "        Baccu.append(temp_accu)\n",
    "        \n",
    "    num_count = []\n",
    "    time_count = []\n",
    "    if config.max_epsilon >= 128:\n",
    "        boost = False\n",
    "    else:\n",
    "        boost = True\n",
    "    print (\"Boost:{0}\".format(boost))\n",
    "    for idx, data in enumerate(test_loader):\n",
    "        if config.dataset_type == 'ImageNet':\n",
    "            input_A, label_A, image_names = data\n",
    "        elif config.dataset_type == 'Cifar10':\n",
    "            input_A, label_A = data\n",
    "            image_names = idx\n",
    "        generator.eval()\n",
    "        input_A = input_A.cuda()\n",
    "        real_A = Variable(input_A, requires_grad=False)\n",
    "        \n",
    "        print(real_A.size())\n",
    "        image_hill = generator(real_A * 0.5 + 0.5) * 0.5 + 0.5\n",
    "        print(image_hill.size())\n",
    "        pre_hill = 1 - image_hill\n",
    "        pre_hill = pre_hill.view(1, 1, -1)\n",
    "       \n",
    "        np_hill = pre_hill.detach().cpu().numpy()\n",
    "        percen = np.percentile(np_hill, 30)\n",
    "        pre_hill = torch.max(pre_hill - percen, torch.zeros(pre_hill.size()).cuda())\n",
    "        np_hill = pre_hill.detach().cpu().numpy()\n",
    "        percen = np.percentile(np_hill, 75)\n",
    "        pre_hill /= percen\n",
    "        pre_hill = torch.clamp(pre_hill, 0, 1)\n",
    "        print(pre_hill.size())\n",
    "        pre_hill = Avg_pool(pre_hill) \n",
    "        SIZE = int(im_size * im_size)\n",
    "        \n",
    "        loss_adv = CWLoss\n",
    "        \n",
    "        logist_B = target_model(real_A)\n",
    "        _, target = torch.max(logist_B, 1)\n",
    "        adv = real_A\n",
    "        ini_num = 1\n",
    "        grad_num = ini_num\n",
    "        mask = torch.zeros(1, 3, SIZE).cuda()\n",
    "\n",
    "        temp_eps = eps / 2\n",
    "\n",
    "        ##### Increasing\n",
    "        for iters in range(Iter):\n",
    "            # print (iters)\n",
    "            temp_A = Variable(adv.data, requires_grad=True)\n",
    "            logist_B = target_model(temp_A)\n",
    "            _, pre = torch.max(logist_B, 1)\n",
    "            \n",
    "            if target.cpu().data.float() != pre.cpu().data.float():\n",
    "                break\n",
    "            Loss = loss_adv(logist_B, target, -100, False) / real_A.size(0)\n",
    "            \n",
    "            target_model.zero_grad()\n",
    "            if temp_A.grad is not None:\n",
    "                temp_A.grad.data.fill_(0)\n",
    "            Loss.backward()\n",
    "            \n",
    "            grad = temp_A.grad\n",
    "            abs_grad = torch.abs(grad).view(1, 3, -1).mean(1, keepdim=True)\n",
    "            print(pre_hill.size())\n",
    "            abs_grad = abs_grad * pre_hill\n",
    "            if not boost:\n",
    "                abs_grad = abs_grad * (1 - mask)\n",
    "            _, grad_sort_idx = torch.sort(abs_grad)\n",
    "            grad_sort_idx = grad_sort_idx.view(-1)\n",
    "            grad_idx = grad_sort_idx[-grad_num:]\n",
    "            mask[0, :, grad_idx] = 1.\n",
    "            temp_mask = mask.view(1, 3, im_size, im_size)\n",
    "            grad = temp_mask * grad\n",
    "            \n",
    "            abs_grad = torch.abs(grad)\n",
    "            abs_grad = abs_grad / torch.max(abs_grad)\n",
    "            normalized_grad = abs_grad * grad.sign()\n",
    "            scaled_grad = normalized_grad.mul(temp_eps)\n",
    "            temp_A = temp_A - scaled_grad\n",
    "            temp_A = clip(temp_A, real_A, eps)\n",
    "            adv = torch.clamp(temp_A, -1, 1)\n",
    "            if boost:\n",
    "                grad_num += ini_num\n",
    "            \n",
    "        final_adv = adv\n",
    "        adv_noise = real_A - final_adv\n",
    "        adv = final_adv\n",
    "        \n",
    "        abs_noise = torch.abs(adv_noise).view(1, 3, -1).mean(1, keepdim=True)\n",
    "        temp_mask = abs_noise != 0\n",
    "        modi_num = torch.sum(temp_mask).data.clone().item()\n",
    "        \n",
    "        reduce_num = modi_num\n",
    "        reduce_count = 0\n",
    "        ###### Reducing\n",
    "        if modi_num > 2:\n",
    "            reduce_idx = 0\n",
    "            while reduce_idx < reduce_num and reduce_count < 3000:\n",
    "                reduce_count += 1\n",
    "                adv_noise = real_A - adv\n",
    "                \n",
    "                abs_noise = torch.abs(adv_noise).view(1, 3, -1).mean(1, keepdim=True)\n",
    "                reduce_mask = abs_noise != 0\n",
    "                reduce_mask = reduce_mask.repeat(1, 3, 1).float()\n",
    "                abs_noise[abs_noise == 0] = 3.\n",
    "                \n",
    "                reduce_num = torch.sum(reduce_mask).data.clone().item() / 3\n",
    "                if reduce_num == 1:\n",
    "                    break\n",
    "                \n",
    "                noise_show, noise_sort_idx = torch.sort(abs_noise)\n",
    "                noise_sort_idx = noise_sort_idx.view( -1)\n",
    "                \n",
    "                noise_idx = noise_sort_idx[reduce_idx]\n",
    "                reduce_mask[0,:,noise_idx] = 0.\n",
    "                temp_mask = reduce_mask.view(1,3,int(im_size),int(im_size))\n",
    "                noise = temp_mask * adv_noise\n",
    "                \n",
    "                abs_noise = torch.abs(noise)\n",
    "                abs_noise = abs_noise / torch.max(abs_noise)\n",
    "                normalized_grad = abs_noise * noise.sign()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    target_model.eval()\n",
    "                    step = int(max(int(config.max_epsilon/10.),1))\n",
    "                    a = [i for i in range(0, int(config.max_epsilon+step), step)]\n",
    "                    search_num = len(a)\n",
    "                    a = np.asarray(a)*2/255. \n",
    "                    ex_temp_eps = torch.from_numpy(a).view(-1,1,1,1).float().cuda()\n",
    "                    ex_normalized_grad = normalized_grad.repeat(int(search_num),1,1,1)\n",
    "                    ex_scaled_grad = ex_normalized_grad.mul(ex_temp_eps)\n",
    "                    ex_real_A = real_A.repeat(int(search_num),1,1,1)\n",
    "                    ex_temp_A = ex_real_A - ex_scaled_grad\n",
    "                    ex_temp_A = clip(ex_temp_A, ex_real_A, eps)\n",
    "                    ex_adv = torch.clamp(ex_temp_A, -1, 1)\n",
    "                    ex_temp_A = Variable(ex_adv.data, requires_grad=False)\n",
    "                    ex_logist_B = target_model(ex_temp_A)\n",
    "                    _,pre=torch.max(ex_logist_B,1)\n",
    "                    comp = torch.eq(target.cpu().data.float(), pre.cpu().data.float())\n",
    "                    top1 = torch.sum(comp).float() / pre.size(0)\n",
    "                    if top1 != 1: ##### exists at least one adversarial sample\n",
    "                        found = False\n",
    "                        for i in range(int(search_num)):\n",
    "                            if comp[i] == 0:\n",
    "                                temp_adv = ex_temp_A[i:i+1]\n",
    "                                logist_B = target_model(temp_adv)\n",
    "                                _,pre=torch.max(logist_B,1)\n",
    "                                new_comp = torch.eq(target.cpu().data.float(), pre.cpu().data.float())\n",
    "                                if torch.sum(new_comp) != 0:\n",
    "                                    continue\n",
    "                                found = True\n",
    "                                adv = temp_adv\n",
    "                                break\n",
    "                        if found == False:\n",
    "                            reduce_idx += 1\n",
    "                    else:\n",
    "                        reduce_idx += 1\n",
    "                        \n",
    "        \n",
    "        adv_noise = real_A - adv\n",
    "        abs_noise = torch.abs(adv_noise).view(1, 3, -1).mean(1, keepdim=True)\n",
    "        temp_mask = abs_noise != 0\n",
    "        \n",
    "        reduce_num = torch.sum(temp_mask).data.clone().item()\n",
    "        L1_X_show = torch.max(torch.abs(real_A - adv)) * 255. / 2\n",
    "\n",
    "        num_count.append(reduce_num)\n",
    "\n",
    "        logist_B = target_model(adv)\n",
    "        _, pre = torch.max(logist_B, 1)\n",
    "        top1 = torch.sum(torch.eq(target.cpu().data.float(), pre.cpu().data.float()).float()) / input_A.size(0)\n",
    "\n",
    "        top1 = torch.from_numpy(np.asarray([(1 - top1)*100])).float().cuda()\n",
    "        Baccu[0].update(top1[0], input_A.size(0))\n",
    "        \n",
    "        print('[{it:.2f}][{name}] '\n",
    "                      'BTOP1: {BTOP1.avg:.2f} '\n",
    "                      'lossX: {ori:d}/{redu:d} '\n",
    "                      'L1: {l1:.1f} '\n",
    "                      'M&m {mean:.2f}/{median:.2f} '\n",
    "                      'Num: {num}'.format(\n",
    "                          it = float(idx*100)/len(test_loader),\n",
    "                          name = image_names[0].split('_')[-1],\n",
    "                          BTOP1 = Baccu[0],\n",
    "                          ori = int(modi_num),\n",
    "                          redu = int(reduce_num),\n",
    "                          l1 = L1_X_show.data.clone().item(),\n",
    "                          num = grad_num,\n",
    "                          mean = np.mean(num_count),\n",
    "                          median = np.median(num_count)))\n",
    "\n",
    "       \n",
    "        if not os.path.exists(root):\n",
    "            os.makedirs(root)\n",
    "        if not os.path.exists(os.path.join(root,'clean')):\n",
    "            os.makedirs(os.path.join(root,'clean'))\n",
    "        if not os.path.exists(os.path.join(root,'adv')):\n",
    "            os.makedirs(os.path.join(root,'adv'))\n",
    "        if not os.path.exists(os.path.join(root,'show')):\n",
    "            os.makedirs(os.path.join(root,'show'))\n",
    "\n",
    "        hill_imgs = pre_hill.view(pre_hill.size(0),1,im_size,im_size).repeat(1,3,1,1)\n",
    "        \n",
    "        if modi_num >= 0.:\n",
    "            for i in range(input_A.size(0)):\n",
    "                clip_img = ToPILImage()((adv[i].data.cpu()+ 1) / 2) \n",
    "                real_img = ToPILImage()((real_A[i].data.cpu()+ 1) / 2)\n",
    "                adv_path = os.path.join(root,'adv' ,image_names[i] +'_' +str(int(modi_num))+'.png')\n",
    "                clip_img.save(adv_path)\n",
    "                real_path = os.path.join(root,'clean', image_names[i] +'_' +str(int(modi_num))+'.png')\n",
    "                real_img.save(real_path)\n",
    "                \n",
    "                if True:\n",
    "                    hill_img = ToPILImage()(hill_imgs[i].data.cpu())\n",
    "                    temp_adv = torch.abs(adv_noise[i].data.cpu())\n",
    "                    temp_adv = temp_adv / torch.max(temp_adv)\n",
    "                    temp_adv = 1 - temp_adv\n",
    "                    adv_img = ToPILImage()(temp_adv)\n",
    "\n",
    "                    temp_hill = image_hill[i].data.cpu()\n",
    "                    \n",
    "                    temp_hill = 1 - temp_hill\n",
    "                    temp_hill = temp_hill.view(1,im_size,im_size).repeat(3,1,1)\n",
    "                    \n",
    "                    temp_hill = ToPILImage()(temp_hill)\n",
    "                    final = Image.fromarray(np.concatenate([temp_hill, hill_img, real_img,adv_img,clip_img],1))\n",
    "                    final.save( os.path.join(root,'show', image_names[i] +'_' +str(int(modi_num))+'.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_net_factory(net_name):\n",
    "    if net_name == 'inception_v3':\n",
    "        netT = inception_v3.inception_v3(pretrained=False)\n",
    "        netT.load_state_dict(torch.load('./checkpoints/inception_v3.pth'))\n",
    "        netT.eval()\n",
    "        netT.cuda()\n",
    "        return netT\n",
    "    elif net_name == 'resnet18':\n",
    "        netT = resnet.ResNet18()\n",
    "        netT = nn.DataParallel(netT).cuda()\n",
    "        netT.load_state_dict(torch.load('./checkpoints/resnet18_cifar10_200.pt'))\n",
    "        return netT\n",
    "    \n",
    "\n",
    "def GanGenerator(dataset_type):\n",
    "    netG = generators.Res_ResnetGenerator(3, 1, 16, norm_type='batch', act_type='relu', dataset_type=dataset_type)\n",
    "    netG = torch.nn.DataParallel(netG, device_ids=range(torch.cuda.device_count()))\n",
    "    netG.load_state_dict(torch.load('./checkpoints/G_imagenet.pth'))\n",
    "    netG.cuda()\n",
    "    netG.eval()\n",
    "    return netG\n",
    "\n",
    "def configuration():\n",
    "    config = Namespace()\n",
    "    config.target_type = 'Untargeted'\n",
    "    config.dataset_type = 'Cifar10'\n",
    "    config.target_model = 'resnet18'\n",
    "    config.iter = 50\n",
    "    config.max_epsilon = 100\n",
    "    config.image_size = 32\n",
    "    config.saving_root = './result/Greedyfool/untargeted/' + config.dataset_type + '/'\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### configuration\n",
    "config = configuration()\n",
    "\n",
    "##### Target model loading\n",
    "netT = target_net_factory(config.target_model)\n",
    "attack_algorithm = attack_factory('greedyfool_w')\n",
    "\n",
    "##### Generator loading for distortion map\n",
    "netG = GanGenerator(config.dataset_type)\n",
    "test_attack_success_rate(config, netT, attack_algorithm, generator=netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
