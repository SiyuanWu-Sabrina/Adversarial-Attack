{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from utils.imagenet_dataset import ImageNetDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToPILImage\n",
    "import models.inception_v3_imagenet as inception_v3\n",
    "import models.generators as generators\n",
    "import models.resnet_cifar10 as resnet\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(no_cuda='False', seed=5, model_path='./checkpoints', test_batch_size=50, target_count=20, target_type=0, target_label=-1)\n"
     ]
    }
   ],
   "source": [
    "sys.argv = ['uniform_testing.ipynb', \n",
    "            '--no-cuda', 'False',\n",
    "            '--seed', '5', \n",
    "            '--model-path', './checkpoints',\n",
    "            '--test-batch-size', '50',\n",
    "            '--target-count', '20',\n",
    "            '--target-type', '0',\n",
    "            '--target-label', '-1'\n",
    "            ]\n",
    "parser = argparse.ArgumentParser(description='Black-box Adversarial Attack')\n",
    "parser.add_argument('--no-cuda', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=0, metavar='S',\n",
    "                    help='random seed (default: 0)')\n",
    "parser.add_argument('--model-path', default='../../checkpoints',\n",
    "                    help='directory of model for saving checkpoint')\n",
    "parser.add_argument('--test-batch-size', type=int, default=50, metavar='N',\n",
    "                    help='input batch size for testing (default: 50)')\n",
    "parser.add_argument('--target-count', type=int, default=20, metavar='N',\n",
    "                    help='the amount of targets(default: 20)')\n",
    "parser.add_argument('--target-type', type=int, default=0, metavar='N',\n",
    "                    help='the method of choosing target label.\\n0: ini_label + 1;\\n1: all the other labels')\n",
    "parser.add_argument('--target-label', type=int, default=-1, metavar='N',\n",
    "                    help='target label, default: -1, which is (ini_label + 1) % 10')\n",
    "args = parser.parse_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify optimization related parameters\n",
    "LR = 0.05  # learning rate\n",
    "EPOCHS = 20  # total optimization epochs\n",
    "NB_SAMPLE = 1000  # number of samples for adjusting lambda\n",
    "MINI_BATCH = NB_SAMPLE // args.test_batch_size  # number of batches\n",
    "INIT_COST = 1e-3  # initial weight of lambda\n",
    "\n",
    "ATTACK_SUCC_THRESHOLD = 0.99  # attack success threshold\n",
    "PATIENCE = 5  # patience for adjusting lambda, number of mini batches\n",
    "COST_MULTIPLIER = 2  # multiplier for auto-control of weight (COST)\n",
    "COST_MULTIPLIER_UP = COST_MULTIPLIER\n",
    "COST_MULTIPLIER_DOWN = 10 ** 0.5  # changed from 2**1.5 to 10**0.5\n",
    "\n",
    "EARLY_STOP_THRESHOLD = 1.0  # loss threshold for early stop\n",
    "EARLY_STOP_PATIENCE = 5 * PATIENCE  # patience for early stop\n",
    "EPSILON = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_factory(dataset_type = 'ImageNet', no_cuda = False, batch_size = 1):\n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "    if dataset_type == 'Cifar10':\n",
    "        kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "        dataset = torchvision.datasets.CIFAR10(\n",
    "            root='./datasets', train=False, download=True, \n",
    "            transform=transforms.Compose([\n",
    "                transforms.CenterCrop(31),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "        )\n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "    elif dataset_type == 'ImageNet':\n",
    "        im_size = 299\n",
    "        mean_arr = (0.5, 0.5, 0.5)\n",
    "        stddev_arr = (0.5, 0.5, 0.5)\n",
    "        dataset = ImageNetDataset(\n",
    "            image_dir='./datasets/imagenet1000',\n",
    "            label_filepath=\"./datasets/imagenet_label.txt\",\n",
    "            transform=transforms.Compose([\n",
    "                transforms.CenterCrop(im_size),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean_arr, stddev_arr)\n",
    "            ]),\n",
    "        )\n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    " \n",
    "\n",
    "def test_attack_success_rate(config, target_model, attack_algorithm, **kwargs):\n",
    "    # sourcery skip: last-if-guard, use-fstring-for-concatenation\n",
    "    \"\"\"This is the unified model for testing attack success rate for adversarial success under a certain configuration.\n",
    "\n",
    "    Args:\n",
    "        config (Namespace): include the attack type(black or white, targeted or untargeted) and other necessary information\n",
    "        target_model: the model to be attacked\n",
    "        data_loader: batch_size = 1\n",
    "    \"\"\"\n",
    "    print(f\"=====Running test on {config.dataset_type} dataset, attacking model {config.target_model}.=====\")\n",
    "    dataloader = data_factory(config.dataset_type)\n",
    "    if config.target_type == 'Untargeted':\n",
    "        result = attack_algorithm(target_model, dataloader, config, **kwargs)  # untargeted attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_factory(attack_algorithm):\n",
    "    mapping = {'B3D_w': B3D_attack_black,\n",
    "               'greedyfool_w': greedyfool_attack_white, \n",
    "               'cornersearch_w': cornersearch_attack_black, \n",
    "               'PGD_attack_w': PGD_attack_white, \n",
    "               'homotopy_w': homotopy_attack_white, \n",
    "               'perturbation_w': perturbation_attack_black}\n",
    "    return mapping[attack_algorithm]\n",
    "\n",
    "def greedyfool_attack_white():\n",
    "    pass\n",
    "\n",
    "def greedyfool_attack_black():\n",
    "    pass\n",
    "\n",
    "def B3D_attack_black():\n",
    "    pass\n",
    "\n",
    "def cornersearch_attack_black():\n",
    "    pass\n",
    "\n",
    "def PGD_attack_white():\n",
    "    pass\n",
    "\n",
    "def homotopy_attack_white():\n",
    "    pass\n",
    "\n",
    "def perturbation_attack_black():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedyfool_attack_white(target_model, test_loader, config, generator):\n",
    "    def clip(adv_A,real_A,eps):\n",
    "        g_x=real_A-adv_A\n",
    "        clip_gx=torch.clamp(g_x, min=-eps, max=eps)\n",
    "        adv_x=real_A-clip_gx\n",
    "        return adv_x\n",
    "    \n",
    "    def CWLoss(logits, target, kappa=0, tar=True if config.target_type == 'Targeted' else False):\n",
    "        if config.dataset_type == 'ImageNet':\n",
    "            target = torch.ones(logits.size(0)).type(torch.cuda.FloatTensor).mul(target.float())\n",
    "            target_one_hot = Variable(torch.eye(1000).type(torch.cuda.FloatTensor)[target.long()].cuda())\n",
    "            \n",
    "            real = torch.sum(target_one_hot*logits, 1)\n",
    "            other = torch.max((1-target_one_hot)*logits - (target_one_hot*10000), 1)[0]\n",
    "            kappa = torch.zeros_like(other).fill_(kappa)\n",
    "        elif config.dataset_type == 'Cifar10':\n",
    "            target = torch.ones(logits.size(0)).type(torch.cuda.FloatTensor).mul(target.float())\n",
    "            target_one_hot = Variable(torch.eye(10).type(torch.cuda.FloatTensor)[target.long()].cuda())\n",
    "            \n",
    "            real = torch.sum(target_one_hot*logits, 1)\n",
    "            other = torch.max((1-target_one_hot)*logits - (target_one_hot*10000), 1)[0]  ## 这里的10000是什么原理\n",
    "            kappa = torch.zeros_like(other).fill_(kappa)\n",
    "        \n",
    "        if tar:\n",
    "            return torch.sum(torch.max(other - real, kappa))\n",
    "        else:\n",
    "            return torch.sum(torch.max(real - other, kappa))\n",
    "    \n",
    "    class AverageMeter(object):\n",
    "        \"\"\"Computes and stores the average and current value\"\"\"\n",
    "        def __init__(self):\n",
    "            self.reset()\n",
    "\n",
    "        def reset(self):\n",
    "            self.val = 0\n",
    "            self.avg = 0\n",
    "            self.sum = 0\n",
    "            self.count = 0\n",
    "\n",
    "        def update(self, val, n=1):\n",
    "            self.val = val\n",
    "            self.sum += val * n\n",
    "            self.count += n\n",
    "            self.avg = self.sum / self.count\n",
    "    \n",
    "    pool_kernel = 3\n",
    "    Avg_pool = nn.AvgPool2d(pool_kernel, stride=1, padding=int(pool_kernel/2))\n",
    "    \n",
    "    print(\"Iter {0}\".format(config.iter))\n",
    "    print(\"EPS {0}\".format(config.max_epsilon))\n",
    "    Iter = config.iter\n",
    "    eps = config.max_epsilon * 2 / 255\n",
    "    im_size = config.image_size\n",
    "    root = config.saving_root\n",
    "    \n",
    "    Baccu = []\n",
    "    for i in range(1):\n",
    "        temp_accu = AverageMeter()\n",
    "        Baccu.append(temp_accu)\n",
    "        \n",
    "    num_count = []\n",
    "    time_count = []\n",
    "    if config.max_epsilon >= 128:\n",
    "        boost = False\n",
    "    else:\n",
    "        boost = True\n",
    "    print (\"Boost:{0}\".format(boost))\n",
    "    for idx, data in enumerate(test_loader):\n",
    "        if config.dataset_type == 'ImageNet':\n",
    "            input_A, label_A, image_names = data\n",
    "        elif config.dataset_type == 'Cifar10':\n",
    "            input_A, label_A = data\n",
    "            image_names = idx\n",
    "        generator.eval()\n",
    "        input_A = input_A.cuda()\n",
    "        real_A = Variable(input_A, requires_grad=False)\n",
    "        \n",
    "        print(real_A.size())\n",
    "        image_hill = generator(real_A * 0.5 + 0.5) * 0.5 + 0.5\n",
    "        print(image_hill.size())\n",
    "        pre_hill = 1 - image_hill\n",
    "        pre_hill = pre_hill.view(1, 1, -1)\n",
    "       \n",
    "        np_hill = pre_hill.detach().cpu().numpy()\n",
    "        percen = np.percentile(np_hill, 30)\n",
    "        pre_hill = torch.max(pre_hill - percen, torch.zeros(pre_hill.size()).cuda())\n",
    "        np_hill = pre_hill.detach().cpu().numpy()\n",
    "        percen = np.percentile(np_hill, 75)\n",
    "        pre_hill /= percen\n",
    "        pre_hill = torch.clamp(pre_hill, 0, 1)\n",
    "        print(pre_hill.size())\n",
    "        pre_hill = Avg_pool(pre_hill) \n",
    "        SIZE = int(im_size * im_size)\n",
    "        \n",
    "        loss_adv = CWLoss\n",
    "        \n",
    "        logist_B = target_model(real_A)\n",
    "        _, target = torch.max(logist_B, 1)\n",
    "        adv = real_A\n",
    "        ini_num = 1\n",
    "        grad_num = ini_num\n",
    "        mask = torch.zeros(1, 3, SIZE).cuda()\n",
    "\n",
    "        temp_eps = eps / 2\n",
    "\n",
    "        ##### Increasing\n",
    "        for iters in range(Iter):\n",
    "            # print (iters)\n",
    "            temp_A = Variable(adv.data, requires_grad=True)\n",
    "            logist_B = target_model(temp_A)\n",
    "            _, pre = torch.max(logist_B, 1)\n",
    "            \n",
    "            if target.cpu().data.float() != pre.cpu().data.float():\n",
    "                break\n",
    "            Loss = loss_adv(logist_B, target, -100, False) / real_A.size(0)\n",
    "            \n",
    "            target_model.zero_grad()\n",
    "            if temp_A.grad is not None:\n",
    "                temp_A.grad.data.fill_(0)\n",
    "            Loss.backward()\n",
    "            \n",
    "            grad = temp_A.grad\n",
    "            abs_grad = torch.abs(grad).view(1, 3, -1).mean(1, keepdim=True)\n",
    "            print(pre_hill.size())\n",
    "            abs_grad = abs_grad * pre_hill\n",
    "            if not boost:\n",
    "                abs_grad = abs_grad * (1 - mask)\n",
    "            _, grad_sort_idx = torch.sort(abs_grad)\n",
    "            grad_sort_idx = grad_sort_idx.view(-1)\n",
    "            grad_idx = grad_sort_idx[-grad_num:]\n",
    "            mask[0, :, grad_idx] = 1.\n",
    "            temp_mask = mask.view(1, 3, im_size, im_size)\n",
    "            grad = temp_mask * grad\n",
    "            \n",
    "            abs_grad = torch.abs(grad)\n",
    "            abs_grad = abs_grad / torch.max(abs_grad)\n",
    "            normalized_grad = abs_grad * grad.sign()\n",
    "            scaled_grad = normalized_grad.mul(temp_eps)\n",
    "            temp_A = temp_A - scaled_grad\n",
    "            temp_A = clip(temp_A, real_A, eps)\n",
    "            adv = torch.clamp(temp_A, -1, 1)\n",
    "            if boost:\n",
    "                grad_num += ini_num\n",
    "            \n",
    "        final_adv = adv\n",
    "        adv_noise = real_A - final_adv\n",
    "        adv = final_adv\n",
    "        \n",
    "        abs_noise = torch.abs(adv_noise).view(1, 3, -1).mean(1, keepdim=True)\n",
    "        temp_mask = abs_noise != 0\n",
    "        modi_num = torch.sum(temp_mask).data.clone().item()\n",
    "        \n",
    "        reduce_num = modi_num\n",
    "        reduce_count = 0\n",
    "        ###### Reducing\n",
    "        if modi_num > 2:\n",
    "            reduce_idx = 0\n",
    "            while reduce_idx < reduce_num and reduce_count < 3000:\n",
    "                reduce_count += 1\n",
    "                adv_noise = real_A - adv\n",
    "                \n",
    "                abs_noise = torch.abs(adv_noise).view(1, 3, -1).mean(1, keepdim=True)\n",
    "                reduce_mask = abs_noise != 0\n",
    "                reduce_mask = reduce_mask.repeat(1, 3, 1).float()\n",
    "                abs_noise[abs_noise == 0] = 3.\n",
    "                \n",
    "                reduce_num = torch.sum(reduce_mask).data.clone().item() / 3\n",
    "                if reduce_num == 1:\n",
    "                    break\n",
    "                \n",
    "                noise_show, noise_sort_idx = torch.sort(abs_noise)\n",
    "                noise_sort_idx = noise_sort_idx.view( -1)\n",
    "                \n",
    "                noise_idx = noise_sort_idx[reduce_idx]\n",
    "                reduce_mask[0,:,noise_idx] = 0.\n",
    "                temp_mask = reduce_mask.view(1,3,int(im_size),int(im_size))\n",
    "                noise = temp_mask * adv_noise\n",
    "                \n",
    "                abs_noise = torch.abs(noise)\n",
    "                abs_noise = abs_noise / torch.max(abs_noise)\n",
    "                normalized_grad = abs_noise * noise.sign()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    target_model.eval()\n",
    "                    step = int(max(int(config.max_epsilon/10.),1))\n",
    "                    a = [i for i in range(0, int(config.max_epsilon+step), step)]\n",
    "                    search_num = len(a)\n",
    "                    a = np.asarray(a)*2/255. \n",
    "                    ex_temp_eps = torch.from_numpy(a).view(-1,1,1,1).float().cuda()\n",
    "                    ex_normalized_grad = normalized_grad.repeat(int(search_num),1,1,1)\n",
    "                    ex_scaled_grad = ex_normalized_grad.mul(ex_temp_eps)\n",
    "                    ex_real_A = real_A.repeat(int(search_num),1,1,1)\n",
    "                    ex_temp_A = ex_real_A - ex_scaled_grad\n",
    "                    ex_temp_A = clip(ex_temp_A, ex_real_A, eps)\n",
    "                    ex_adv = torch.clamp(ex_temp_A, -1, 1)\n",
    "                    ex_temp_A = Variable(ex_adv.data, requires_grad=False)\n",
    "                    ex_logist_B = target_model(ex_temp_A)\n",
    "                    _,pre=torch.max(ex_logist_B,1)\n",
    "                    comp = torch.eq(target.cpu().data.float(), pre.cpu().data.float())\n",
    "                    top1 = torch.sum(comp).float() / pre.size(0)\n",
    "                    if top1 != 1: ##### exists at least one adversarial sample\n",
    "                        found = False\n",
    "                        for i in range(int(search_num)):\n",
    "                            if comp[i] == 0:\n",
    "                                temp_adv = ex_temp_A[i:i+1]\n",
    "                                logist_B = target_model(temp_adv)\n",
    "                                _,pre=torch.max(logist_B,1)\n",
    "                                new_comp = torch.eq(target.cpu().data.float(), pre.cpu().data.float())\n",
    "                                if torch.sum(new_comp) != 0:\n",
    "                                    continue\n",
    "                                found = True\n",
    "                                adv = temp_adv\n",
    "                                break\n",
    "                        if found == False:\n",
    "                            reduce_idx += 1\n",
    "                    else:\n",
    "                        reduce_idx += 1\n",
    "                        \n",
    "        \n",
    "        adv_noise = real_A - adv\n",
    "        abs_noise = torch.abs(adv_noise).view(1, 3, -1).mean(1, keepdim=True)\n",
    "        temp_mask = abs_noise != 0\n",
    "        \n",
    "        reduce_num = torch.sum(temp_mask).data.clone().item()\n",
    "        L1_X_show = torch.max(torch.abs(real_A - adv)) * 255. / 2\n",
    "\n",
    "        num_count.append(reduce_num)\n",
    "\n",
    "        logist_B = target_model(adv)\n",
    "        _, pre = torch.max(logist_B, 1)\n",
    "        top1 = torch.sum(torch.eq(target.cpu().data.float(), pre.cpu().data.float()).float()) / input_A.size(0)\n",
    "\n",
    "        top1 = torch.from_numpy(np.asarray([(1 - top1)*100])).float().cuda()\n",
    "        Baccu[0].update(top1[0], input_A.size(0))\n",
    "        \n",
    "        print('[{it:.2f}][{name}] '\n",
    "                      'BTOP1: {BTOP1.avg:.2f} '\n",
    "                      'lossX: {ori:d}/{redu:d} '\n",
    "                      'L1: {l1:.1f} '\n",
    "                      'M&m {mean:.2f}/{median:.2f} '\n",
    "                      'Num: {num}'.format(\n",
    "                          it = float(idx*100)/len(test_loader),\n",
    "                          name = image_names[0].split('_')[-1],\n",
    "                          BTOP1 = Baccu[0],\n",
    "                          ori = int(modi_num),\n",
    "                          redu = int(reduce_num),\n",
    "                          l1 = L1_X_show.data.clone().item(),\n",
    "                          num = grad_num,\n",
    "                          mean = np.mean(num_count),\n",
    "                          median = np.median(num_count)))\n",
    "\n",
    "       \n",
    "        if not os.path.exists(root):\n",
    "            os.makedirs(root)\n",
    "        if not os.path.exists(os.path.join(root,'clean')):\n",
    "            os.makedirs(os.path.join(root,'clean'))\n",
    "        if not os.path.exists(os.path.join(root,'adv')):\n",
    "            os.makedirs(os.path.join(root,'adv'))\n",
    "        if not os.path.exists(os.path.join(root,'show')):\n",
    "            os.makedirs(os.path.join(root,'show'))\n",
    "\n",
    "        hill_imgs = pre_hill.view(pre_hill.size(0),1,im_size,im_size).repeat(1,3,1,1)\n",
    "        \n",
    "        if modi_num >= 0.:\n",
    "            for i in range(input_A.size(0)):\n",
    "                clip_img = ToPILImage()((adv[i].data.cpu()+ 1) / 2) \n",
    "                real_img = ToPILImage()((real_A[i].data.cpu()+ 1) / 2)\n",
    "                adv_path = os.path.join(root,'adv' ,image_names[i] +'_' +str(int(modi_num))+'.png')\n",
    "                clip_img.save(adv_path)\n",
    "                real_path = os.path.join(root,'clean', image_names[i] +'_' +str(int(modi_num))+'.png')\n",
    "                real_img.save(real_path)\n",
    "                \n",
    "                if True:\n",
    "                    hill_img = ToPILImage()(hill_imgs[i].data.cpu())\n",
    "                    temp_adv = torch.abs(adv_noise[i].data.cpu())\n",
    "                    temp_adv = temp_adv / torch.max(temp_adv)\n",
    "                    temp_adv = 1 - temp_adv\n",
    "                    adv_img = ToPILImage()(temp_adv)\n",
    "\n",
    "                    temp_hill = image_hill[i].data.cpu()\n",
    "                    \n",
    "                    temp_hill = 1 - temp_hill\n",
    "                    temp_hill = temp_hill.view(1,im_size,im_size).repeat(3,1,1)\n",
    "                    \n",
    "                    temp_hill = ToPILImage()(temp_hill)\n",
    "                    final = Image.fromarray(np.concatenate([temp_hill, hill_img, real_img,adv_img,clip_img],1))\n",
    "                    final.save( os.path.join(root,'show', image_names[i] +'_' +str(int(modi_num))+'.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homotopy_attack_white(target_model, test_loader, config):\n",
    "    def CWLoss(logits, target, kappa=0, tar = True):\n",
    "        target = torch.ones(logits.size(0)).type(torch.cuda.FloatTensor).mul(target.float())\n",
    "        target_one_hot = Variable(torch.eye(1000).type(torch.cuda.FloatTensor)[target.long()].cuda())\n",
    "        \n",
    "        real = torch.sum(target_one_hot*logits, 1)\n",
    "        other = torch.max((1-target_one_hot)*logits - (target_one_hot*10000), 1)[0]\n",
    "        kappa = torch.zeros_like(other).fill_(kappa)\n",
    "        \n",
    "        if tar:\n",
    "            return torch.sum(torch.max(other-real, kappa))\n",
    "        else :\n",
    "            return torch.sum(torch.max(real-other, kappa))\n",
    "    \n",
    "    def after_attack(x, net, original_img, original_class, target_class, post, loss_type, tar, iters, val_w1, val_w2, max_epsilon):\n",
    "\n",
    "        if post == 1:\n",
    "            s1 = 1e-3\n",
    "            s2 = 1e-4\n",
    "            max_iter = 40000\n",
    "        else:\n",
    "            s1 = val_w2\n",
    "            s2 = val_w1\n",
    "            max_iter = iters\n",
    "\n",
    "        mask = torch.where(torch.abs(x.data) > 0, torch.ones(1).cuda(), torch.zeros(1).cuda())\n",
    "\n",
    "        logist = net(x.data+original_img.data)\n",
    "        _,target=torch.max(logist,1)\n",
    "\n",
    "\n",
    "        pre_x = x.data\n",
    "\n",
    "        for i in range(max_iter):\n",
    "\n",
    "            temp = Variable(x.data, requires_grad=True)\n",
    "            logist = net(temp + original_img.data)\n",
    "            if tar == 1:\n",
    "                if loss_type == 'ce':\n",
    "                    ce = torch.nn.CrossEntropyLoss()\n",
    "                    Loss = ce(logist,torch.ones(1).long().cuda()*target_class)\n",
    "                elif loss_type == 'cw':\n",
    "                    Loss = CWLoss(logist, torch.ones(1).long().cuda()*target_class, kappa=0, tar = True)\n",
    "            else:\n",
    "                Loss = CWLoss(logist, torch.ones(1).long().cuda()*target_class, kappa=0, tar = False)\n",
    "\n",
    "            net.zero_grad()\n",
    "            if temp.grad is not None:\n",
    "                temp.grad.data.fill_(0)\n",
    "            Loss.backward()\n",
    "            grad = temp.grad\n",
    "\n",
    "        \n",
    "            temp2 = Variable(x.data, requires_grad=True)\n",
    "            Loss2 = torch.norm(temp2, p=float(\"inf\"))\n",
    "            net.zero_grad()\n",
    "            if temp2.grad is not None:\n",
    "                temp2.grad.data.fill_(0)\n",
    "            Loss2.backward()\n",
    "            grad2 = temp2.grad\n",
    "\n",
    "\n",
    "            pre_x = x.data\n",
    "\n",
    "            pre_noise = temp2.data\n",
    "            if post == 0:\n",
    "                temp2 = temp2.data - s1*grad2.data*mask - s2*grad.data*mask\n",
    "            else:\n",
    "                temp2 = temp2.data - s1*grad2.data*mask\n",
    "\n",
    "            thres = max_epsilon\n",
    "            temp2 = torch.clamp(temp2.data, -thres, thres)\n",
    "            temp2 = torch.clamp(original_img.data+temp2.data, 0, 1)\n",
    "        \n",
    "            x = temp2.data - original_img.data\n",
    "        \n",
    "\n",
    "            logist = net(x.data + original_img.data)\n",
    "            _,pre=torch.max(logist,1)\n",
    "            if(post == 1):\n",
    "                if tar ==  1:\n",
    "                    if(pre.item() != target_class):\n",
    "                        success = 1\n",
    "                        return pre_x\n",
    "                        break\n",
    "                else:\n",
    "                    if(pre.item() == target_class):\n",
    "                        success = 1\n",
    "                        return pre_x\n",
    "                        break\n",
    "\n",
    "        return x\n",
    "\n",
    "    def F(x, loss_type, net, lambda1, original_img, target_class, tar):\n",
    "        temp = Variable(x.data, requires_grad=False)\n",
    "        logist = net(temp+original_img.data)\n",
    "        if tar == 1:\n",
    "            if loss_type == 'ce':\n",
    "                ce = torch.nn.CrossEntropyLoss()\n",
    "                Loss = ce(logist,torch.ones(1).long().cuda()*target_class)\n",
    "            elif loss_type == 'cw':\n",
    "                Loss = CWLoss(logist, torch.ones(1).long().cuda()*target_class, kappa=0, tar = True)\n",
    "        else:\n",
    "            Loss = CWLoss(logist, torch.ones(1).long().cuda()*target_class, kappa=0, tar = False)\n",
    "        res = Loss.item() + lambda1*torch.norm(x.data,0).item()\n",
    "        net.zero_grad()\n",
    "        return res\n",
    "\n",
    "    def prox_pixel(x, alpha, lambda1, original_img, max_epsilon):\n",
    "\n",
    "        temp_x = x.data * torch.ones(x.shape).cuda()\n",
    "\n",
    "        thres = max_epsilon\n",
    "        clamp_x = torch.clamp(temp_x.data, -thres, thres)\n",
    "\n",
    "        temp_img = original_img.data + clamp_x.data\n",
    "        temp_img = torch.clamp(temp_img.data, 0, 1)\n",
    "        clamp_x = temp_img.data - original_img.data\n",
    "\n",
    "        val = 1 / (2*alpha*lambda1)\n",
    "        cond = 1 + val * (clamp_x-temp_x)*(clamp_x-temp_x) > val * temp_x*temp_x\n",
    "        cond = cond.cuda()\n",
    "\n",
    "        res = torch.zeros(x.shape).cuda()\n",
    "        res = torch.where(cond, res, clamp_x.data)\n",
    "        return res\n",
    "\n",
    "    def nmAPG(x0, loss_type, net, eta, delta, rho, original_img, lambda1, search_lambda_inc, search_lambda_dec, target_class, original_class, tar, max_update, maxiter, max_epsilon):\n",
    "\n",
    "        x0_norm0 = torch.norm(torch.ones(x0.shape).cuda()*x0.data,0).item()\n",
    "        max_update = max_update\n",
    "\n",
    "        temp = Variable(x0.data, requires_grad=False)\n",
    "        logist = net(temp+original_img.data)\n",
    "        if tar == 1:\n",
    "            if loss_type == 'ce':\n",
    "                ce = torch.nn.CrossEntropyLoss()\n",
    "                Loss = ce(logist, torch.ones(1).long().cuda()*target_class)\n",
    "            elif loss_type == 'cw':\n",
    "                Loss = CWLoss(logist, torch.ones(1).long().cuda()*target_class, kappa=0, tar=True)\n",
    "        else:\n",
    "            Loss = CWLoss(logist, torch.ones(1).long().cuda()*target_class, kappa=0, tar=False)\n",
    "        net.zero_grad()\n",
    "\n",
    "        z = x0\n",
    "        y_pre = torch.zeros(original_img.shape).cuda()\n",
    "\n",
    "        pre_loss = 0\n",
    "        cur_loss = 0\n",
    "\n",
    "        counter = 0\n",
    "        success = 0\n",
    "\n",
    "        alpha_y = 1e-3\n",
    "        alpha_x = 1e-3\n",
    "\n",
    "        alpha_min = 1e-20\n",
    "        alpha_max = 1e20\n",
    "        x_pre = x0\n",
    "        x = x0\n",
    "        t = 1\n",
    "        t_pre = 0\n",
    "        c = Loss + lambda1*torch.norm(x.data,0)\n",
    "        q = 1\n",
    "        k = 0\n",
    "        while True:\n",
    "            y = x + t_pre/t*(z-x) + (t_pre-1)/t*(x-x_pre)\n",
    "\n",
    "            if k > 0:\n",
    "                s = y - y_pre.data\n",
    "\n",
    "                #gradient of yk\n",
    "                temp_y = Variable(y.data, requires_grad=True)\n",
    "                logist_y = net(temp_y+original_img.data)\n",
    "                if tar == 1:\n",
    "                    if loss_type == 'ce':\n",
    "                        ce = torch.nn.CrossEntropyLoss()\n",
    "                        Loss_y = ce(logist_y, torch.ones(1).long().cuda()*target_class)\n",
    "                    elif loss_type == 'cw':\n",
    "                        Loss_y = CWLoss(logist_y, torch.ones(1).long().cuda()*target_class, kappa=0, tar = True)\n",
    "                else:\n",
    "                    Loss_y = CWLoss(logist_y, torch.ones(1).long().cuda()*target_class, kappa=0, tar = False)\n",
    "                net.zero_grad()\n",
    "                if temp_y.grad is not None:\n",
    "                    temp_y.grad.data.fill_(0)\n",
    "                Loss_y.backward() \n",
    "                grad_y = temp_y.grad\n",
    "\n",
    "                #gradient of yk-1\n",
    "                temp_y_pre = Variable(y_pre.data, requires_grad=True)\n",
    "                logist_y_pre = net(temp_y_pre+original_img.data)\n",
    "                if tar == 1:\n",
    "                    if loss_type == 'ce':\n",
    "                        ce = torch.nn.CrossEntropyLoss()\n",
    "                        Loss_y_pre = ce(logist_y_pre, torch.ones(1).long().cuda()*target_class)\n",
    "                    elif loss_type == 'cw':\n",
    "                        Loss_y_pre = CWLoss(logist_y_pre, torch.ones(1).long().cuda()*target_class, kappa=0, tar = True)\n",
    "                else:\n",
    "                    Loss_y_pre = CWLoss(logist_y_pre, torch.ones(1).long().cuda()*target_class, kappa=0, tar = False)\n",
    "                net.zero_grad()\n",
    "                if temp_y_pre.grad is not None:\n",
    "                    temp_y_pre.grad.data.fill_(0)\n",
    "                Loss_y_pre.backward() \n",
    "                grad_y_pre = temp_y_pre.grad\n",
    "\n",
    "                r = grad_y - grad_y_pre\n",
    "                \n",
    "                #prevent error caused by numerical inaccuracy\n",
    "                if torch.norm(s,1) < 1e-5:\n",
    "                    s = torch.ones(1).cuda()*1e-5\n",
    "                \n",
    "                if torch.norm(r,1) < 1e-10:\n",
    "                    r = torch.ones(1).cuda()*1e-10\n",
    "\n",
    "                alpha_y = torch.sum(s*r)/torch.sum(r*r)\n",
    "                alpha_y = alpha_y.item()\n",
    "            \n",
    "            temp_alpha = alpha_y\n",
    "\n",
    "            if temp_alpha < alpha_min:\n",
    "                temp_alpha = alpha_min\n",
    "\n",
    "            if temp_alpha > alpha_max:\n",
    "                temp_alpha = alpha_max\n",
    "\n",
    "            if np.isnan(temp_alpha):\n",
    "                temp_alpha = alpha_min\n",
    "            alpha_y = temp_alpha\n",
    "\n",
    "            count1 = 0\n",
    "            while True:\n",
    "                count1 = count1 + 1\n",
    "                if count1 > 1000:\n",
    "                    break\n",
    "\n",
    "                temp_y = Variable(y.data, requires_grad=True)\n",
    "                logist_y = net(temp_y+original_img.data)\n",
    "                if tar == 1:\n",
    "                    if loss_type == 'ce':\n",
    "                        ce = torch.nn.CrossEntropyLoss()\n",
    "                        Loss_y = ce(logist_y,torch.ones(1).long().cuda()*target_class)\n",
    "                    elif loss_type == 'cw':\n",
    "                        Loss_y = CWLoss(logist_y, torch.ones(1).long().cuda()*target_class, kappa=0, tar = True)\n",
    "                else:\n",
    "                    Loss_y = CWLoss(logist_y, torch.ones(1).long().cuda()*target_class, kappa=0, tar = False)\n",
    "                net.zero_grad()\n",
    "                if temp_y.grad is not None:\n",
    "                    temp_y.grad.data.fill_(0)\n",
    "                Loss_y.backward() \n",
    "                grad_y = temp_y.grad\n",
    "\n",
    "                z = prox_pixel(x=y-alpha_y*grad_y,alpha=alpha_y,lambda1=lambda1,original_img=original_img, max_epsilon=max_epsilon)\n",
    "                \n",
    "                #increase lambda\n",
    "                if(search_lambda_inc == 1):\n",
    "                    if(torch.norm(z,1) != 0):\n",
    "                        return 0\n",
    "                    else:\n",
    "                        return 1\n",
    "\n",
    "                #decrease lambda\n",
    "                if(search_lambda_dec == 1):\n",
    "                    if(torch.norm(z,1) == 0):\n",
    "                        return 0\n",
    "                    else:\n",
    "                        return lambda1\n",
    "\n",
    "                alpha_y = alpha_y * rho\n",
    "                cond1 = F(z, loss_type, net, lambda1, original_img,target_class,tar) <= F(y, loss_type, net, lambda1, original_img,target_class,tar) - delta*(torch.norm(z-y,2)*torch.norm(z-y,2))\n",
    "                cond2 = F(z, loss_type, net, lambda1, original_img,target_class,tar) <= c - delta*(torch.norm(z-y,2)*torch.norm(z-y,2))\n",
    "\n",
    "                if(cond1 | cond2):\n",
    "                    break\n",
    "            \n",
    "            if F(z, loss_type, net, lambda1, original_img,target_class,tar) <= c - delta*(torch.norm(z-y,2)*torch.norm(z-y,2)):\n",
    "                x_pre = x\n",
    "                temp_norm0 = torch.norm(torch.ones(z.shape).cuda()*z.data,0).item()\n",
    "                if np.abs(temp_norm0 - x0_norm0) > max_update:\n",
    "                    temp_z = torch.abs((torch.ones(z.shape).cuda()*z.data).reshape(1,-1))\n",
    "                    val, idx = temp_z.topk(k=int(x0_norm0+max_update))\n",
    "\n",
    "                    thres = val[0,int(x0_norm0+max_update-1)]\n",
    "                    z = torch.where(torch.abs(z.data) < thres, torch.zeros(1).cuda(), z.data)\n",
    "                    x = z\n",
    "                else:\n",
    "                    x = z\n",
    "            else:\n",
    "\n",
    "                if k > 0:\n",
    "                    s = x - y_pre.data\n",
    "\n",
    "                    temp_x = Variable(x.data, requires_grad=True)\n",
    "                    logist_x = net(temp_x+original_img.data)\n",
    "                    if tar == 1:\n",
    "                        if loss_type == 'ce':\n",
    "                            ce = torch.nn.CrossEntropyLoss()\n",
    "                            Loss_x = ce(logist_x,torch.ones(1).long().cuda()*target_class)\n",
    "                        elif loss_type == 'cw':\n",
    "                            Loss_x = CWLoss(logist_x, torch.ones(1).long().cuda()*target_class, kappa=0, tar = True)\n",
    "                    else:\n",
    "                        Loss_x = CWLoss(logist_x, torch.ones(1).long().cuda()*target_class, kappa=0, tar = False)\n",
    "                    net.zero_grad()\n",
    "                    if temp_x.grad is not None:\n",
    "                        temp_x.grad.data.fill_(0)\n",
    "                    Loss_x.backward() \n",
    "                    grad_x = temp_x.grad\n",
    "\n",
    "                    temp_y_pre = Variable(y_pre.data, requires_grad=True)\n",
    "                    logist_y_pre = net(temp_y_pre+original_img.data)\n",
    "                    if tar == 1:\n",
    "                        if loss_type == 'ce':\n",
    "                            ce = torch.nn.CrossEntropyLoss()\n",
    "                            Loss_y_pre = ce(logist_y_pre,torch.ones(1).long().cuda()*target_class)\n",
    "                        elif loss_type == 'cw':\n",
    "                            Loss_y_pre = CWLoss(logist_y_pre, torch.ones(1).long().cuda()*target_class, kappa=0, tar = True)\n",
    "                    else:\n",
    "                        Loss_y_pre = CWLoss(logist_y_pre, torch.ones(1).long().cuda()*target_class, kappa=0, tar = False)\n",
    "                    net.zero_grad()\n",
    "                    if temp_y_pre.grad is not None:\n",
    "                        temp_y_pre.grad.data.fill_(0)\n",
    "                    Loss_y_pre.backward() \n",
    "                    grad_y_pre = temp_y_pre.grad\n",
    "                \n",
    "                    r = grad_x - grad_y_pre\n",
    "\n",
    "                    if torch.norm(s, 1) < 1e-5:\n",
    "                        s = torch.ones(1).cuda() * 1e-5\n",
    "\n",
    "                    if torch.norm(r,1) < 1e-10:\n",
    "                        r = torch.ones(1).cuda()*1e-10\n",
    "                    \n",
    "                    alpha_x = torch.sum(s*r)/torch.sum(r*r)\n",
    "                    alpha_x = alpha_x.item()\n",
    "\n",
    "                temp_alpha = alpha_x\n",
    "\n",
    "            \n",
    "                if temp_alpha < alpha_min:\n",
    "                    temp_alpha = alpha_min\n",
    "\n",
    "                if temp_alpha > alpha_max:\n",
    "                    temp_alpha = alpha_max\n",
    "                if np.isnan(temp_alpha):\n",
    "                    temp_alpha = alpha_min\n",
    "                alpha_x = temp_alpha\n",
    "\n",
    "                count2 = 0\n",
    "                while True:\n",
    "                    count2 = count2 + 1\n",
    "\n",
    "                    if count2 > 10:\n",
    "                        break\n",
    "\n",
    "                    temp_x = Variable(x.data, requires_grad=True)\n",
    "                    logist_x = net(temp_x + original_img.data)\n",
    "                    if tar == 1:\n",
    "                        if loss_type == 'ce':\n",
    "                            ce = torch.nn.CrossEntropyLoss()\n",
    "                            Loss_x = ce(logist_x, torch.ones(1).long().cuda() * target_class)\n",
    "                        elif loss_type == 'cw':\n",
    "                            Loss_x = CWLoss(logist_x, torch.ones(1).long().cuda() * target_class, kappa=0, tar=True)\n",
    "                    else:\n",
    "                        Loss_x = CWLoss(logist_x, torch.ones(1).long().cuda() * target_class, kappa=0, tar=False)\n",
    "                    net.zero_grad()\n",
    "                    if temp_x.grad is not None:\n",
    "                        temp_x.grad.data.fill_(0)\n",
    "                    Loss_x.backward()\n",
    "                    grad_x = temp_x.grad\n",
    "\n",
    "                    v = prox_pixel(x=x-alpha_x*grad_x,alpha=alpha_x,lambda1=lambda1,original_img=original_img, max_epsilon=max_epsilon)\n",
    "                    alpha_x = rho * alpha_x\n",
    "                    cond3 = F(v, loss_type, net, lambda1, original_img,target_class,tar) <= c - delta*(torch.norm(v-x,2)*torch.norm(v-x,2))\n",
    "\n",
    "                    if cond3:\n",
    "                        break\n",
    "                    if torch.abs(F(v, loss_type, net, lambda1, original_img,target_class,tar) - (c - delta*(torch.norm(v-x,2)*torch.norm(v-x,2)) )) < 1e-3:\n",
    "                        break\n",
    "\n",
    "                \n",
    "                if F(z, loss_type, net, lambda1, original_img,target_class,tar) <= F(v, loss_type, net, lambda1, original_img,target_class,tar):\n",
    "                    x_pre = x\n",
    "                    temp_norm0 = torch.norm(torch.ones(z.shape).cuda() * z.data, 0).item()\n",
    "                    if np.abs(temp_norm0 - x0_norm0) > max_update:\n",
    "                        temp_z = torch.abs((torch.ones(z.shape).cuda() * z.data).reshape(1, -1))\n",
    "                        val, idx = temp_z.topk(k=int(x0_norm0 + max_update))\n",
    "\n",
    "                        thres = val[0, int(x0_norm0 + max_update - 1)]\n",
    "                        z = torch.where(torch.abs(z.data) < thres, torch.zeros(1).cuda(), z.data)\n",
    "                        x = z\n",
    "                    else:\n",
    "                        x = z\n",
    "                else:\n",
    "                    x_pre = x\n",
    "                    temp_norm0 = torch.norm(torch.ones(v.shape).cuda() * v.data, 0).item()\n",
    "                    if np.abs(temp_norm0 - x0_norm0) > max_update:\n",
    "                        temp_v = torch.abs((torch.ones(v.shape).cuda() * v.data).reshape(1, -1))\n",
    "                        val, idx = temp_v.topk(k=int(x0_norm0 + max_update))\n",
    "                        thres = val[0, int(x0_norm0 + max_update - 1)]\n",
    "                        v = torch.where(torch.abs(v.data) < thres, torch.zeros(1).cuda(), v.data)\n",
    "                        x = v\n",
    "                    else:\n",
    "                        x = v\n",
    "\n",
    "\n",
    "            thres = max_epsilon\n",
    "            x = torch.clamp(x.data,-thres,thres)\n",
    "            temp_img = original_img.data + x.data\n",
    "            temp_img = torch.clamp(temp_img.data, 0, 1)\n",
    "            x = temp_img.data - original_img.data\n",
    "\n",
    "            y_pre = y.data\n",
    "            t = (np.sqrt(4*t*t+1)+1)/2\n",
    "            q = eta*q + 1\n",
    "            c = (eta*q*c + F(x, loss_type, net, lambda1, original_img,target_class,tar))/q\n",
    "\n",
    "            logist = net(x.data+original_img.data)\n",
    "            _,target=torch.max(logist,1)\n",
    "\n",
    "            k = k + 1\n",
    "\n",
    "            pre_loss = cur_loss\n",
    "\n",
    "            if tar == 0:\n",
    "                cur_loss = CWLoss(logist.data, torch.ones(1).long().cuda()*target_class, kappa=0, tar = False).item()\n",
    "            else:\n",
    "                if loss_type == 'cw':\n",
    "                    cur_loss = CWLoss(logist.data, torch.ones(1).long().cuda()*target_class, kappa=0, tar = True).item()\n",
    "                else:\n",
    "                    ce = torch.nn.CrossEntropyLoss()\n",
    "                    cur_loss = ce(logist.data, torch.ones(1).long().cuda() * target_class).item()\n",
    "            net.zero_grad()\n",
    "\n",
    "            #success\n",
    "            if tar == 1:\n",
    "                if (target == target_class):\n",
    "                    success = 1\n",
    "                    break\n",
    "            else:\n",
    "                if ((target != target_class)):\n",
    "                    success = 1\n",
    "                    break\n",
    "\n",
    "            if ((success == 0) and (k >= maxiter) and (np.abs(pre_loss-cur_loss) < 1e-3) and (counter==1)):\n",
    "                break\n",
    "\n",
    "            if((k >= maxiter) and (np.abs(pre_loss-cur_loss) < 1e-3)):\n",
    "                counter = 1\n",
    "\n",
    "        return x, success\n",
    "\n",
    "    def search_lambda(loss_type, net, original_img, target_class, original_class, tar, val_c, max_update, maxiter, max_epsilon):\n",
    "\n",
    "        lambda1 = 1e-6\n",
    "        x0 = torch.zeros(original_img.shape).cuda()\n",
    "        k1 = 0\n",
    "        while True:\n",
    "            k1 = k1 + 1\n",
    "            temp = nmAPG(x0=x0, loss_type=loss_type, net=net, eta=0.9, delta=0.3, rho=0.8, original_img=original_img, lambda1=lambda1,\n",
    "                        search_lambda_inc=1, search_lambda_dec=0, target_class=target_class, original_class=original_class, tar=tar, max_update=max_update, maxiter=maxiter, max_epsilon=max_epsilon)\n",
    "            if temp == 0:\n",
    "                lambda1 = lambda1 + 1e-6\n",
    "            if temp == 1:\n",
    "                break\n",
    "\n",
    "        k2 = 0\n",
    "        while True:\n",
    "            k2 = k2 + 1\n",
    "            temp = nmAPG(x0=x0, loss_type=loss_type, net=net, eta=0.9, delta=0.3, rho=0.8, original_img=original_img, lambda1=lambda1,\n",
    "                        search_lambda_inc=0, search_lambda_dec=1, target_class=target_class, original_class=original_class, tar=tar,max_update=max_update, maxiter=maxiter, max_epsilon=max_epsilon)\n",
    "            if temp == 0:\n",
    "                lambda1 = lambda1 * 0.99\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        lambda1 = lambda1 * val_c\n",
    "        print('attack lambda = ', lambda1)\n",
    "\n",
    "        return lambda1\n",
    "\n",
    "    def homotopy(loss_type, net, original_img, target_class, original_class, tar, max_epsilon, dec_factor, val_c, val_w1, val_w2, max_update, maxiter, val_gamma):\n",
    "\n",
    "        lambda1 = search_lambda(loss_type, net, original_img, target_class, original_class,tar, val_c, max_update, maxiter, max_epsilon=max_epsilon)\n",
    "\n",
    "        x = torch.zeros(original_img.shape).cuda()\n",
    "        pre_norm0 = 0\n",
    "        cur_norm0 = 0\n",
    "\n",
    "        max_norm0 = torch.norm(torch.ones(x.shape).cuda(),0).item()\n",
    "        outer_iter = 0\n",
    "        val_max_update = max_update\n",
    "        while True:\n",
    "            outer_iter = outer_iter + 1\n",
    "\n",
    "            x, success = nmAPG(x0=x, loss_type=loss_type, net=net, eta=0.9, delta=0.3, rho=0.8, original_img=original_img, lambda1=lambda1,\n",
    "                            search_lambda_inc=0, search_lambda_dec=0, target_class=target_class, original_class=original_class, tar=tar, max_update=max_update, maxiter=maxiter, max_epsilon=max_epsilon)\n",
    "            max_update = val_max_update\n",
    "            pre_norm0 = cur_norm0\n",
    "            cur_norm0 = torch.norm(torch.ones(x.shape).cuda()*x.data,0).item()\n",
    "            cur_norm1 = torch.norm(torch.ones(x.shape).cuda() * x.data, 1).item()\n",
    "\n",
    "            #attack fail\n",
    "            if(cur_norm0 > max_norm0*0.95 and outer_iter*max_update > max_norm0*0.95):\n",
    "                break\n",
    "\n",
    "            iters = 0\n",
    "            if (cur_norm1 <= cur_norm0 * max_epsilon * val_gamma):\n",
    "                max_update = 10\n",
    "                iters = 200\n",
    "                if cur_norm0 >= 500:\n",
    "                    iters = 400\n",
    "                if cur_norm0 >= 1000:\n",
    "                    iters = 600\n",
    "                if cur_norm0 >= 1500:\n",
    "                    iters = 800\n",
    "                if cur_norm0 >= 2000:\n",
    "                    iters = 1000\n",
    "                if cur_norm0 >= 2500:\n",
    "                    iters = 1200\n",
    "\n",
    "            if success == 0:\n",
    "                x = after_attack(x, net, original_img, original_class, target_class, post=0, loss_type=loss_type, tar=tar, iters=iters, val_w1=val_w1, val_w2=val_w2, max_epsilon=max_epsilon)\n",
    "                lambda1 = dec_factor * lambda1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "            logi = net(x.data+original_img.data)\n",
    "            _,cur_class=torch.max(logi,1)\n",
    "            if tar == 1:\n",
    "                if((cur_class == target_class)):\n",
    "                    break\n",
    "            else:\n",
    "                if((cur_class != target_class)):\n",
    "                    break\n",
    "\n",
    "        x = after_attack(x, net, original_img, original_class, target_class, post=1, loss_type=loss_type,tar=tar, iters=iters, val_w1=val_w1, val_w2=val_w2, max_epsilon=max_epsilon)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): Res_ResnetGenerator(\n",
      "    (act): ReLU(inplace=True)\n",
      "    (res1): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (res2): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (res3): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (res4): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (res5): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (res6): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (En): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (5): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (6): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (10): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (11): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (13): ReLU(inplace=True)\n",
      "    )\n",
      "    (Dn): Sequential(\n",
      "      (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (4): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (5): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): ReLU(inplace=True)\n",
      "      (8): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (9): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (10): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (11): Conv2d(16, 1, kernel_size=(8, 8), stride=(1, 1))\n",
      "      (12): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "\n",
    "##### Target model loading\n",
    "# netT = models.inception_v3(pretrained=True)\n",
    "netT = inception_v3.inception_v3(pretrained=False) # 可以该做resnet18\n",
    "netT.load_state_dict(torch.load('./checkpoints/inception_v3.pth'))\n",
    "netT.eval()\n",
    "netT.cuda()\n",
    "\n",
    "##### Generator loading for distortion map\n",
    "netG = generators.Res_ResnetGenerator(3, 1, 16, norm_type='batch', act_type='relu')\n",
    "netG = torch.nn.DataParallel(netG, device_ids=range(torch.cuda.device_count()))\n",
    "netG.load_state_dict(torch.load('./checkpoints/G_imagenet.pth'))\n",
    "print(netG)\n",
    "netG.cuda()\n",
    "netG.eval()\n",
    "\n",
    "def GanGenerator(dataset_type):\n",
    "    netG = generators.Res_ResnetGenerator(3, 1, 16, norm_type='batch', act_type='relu', dataset_type=dataset_type)\n",
    "    netG = torch.nn.DataParallel(netG, device_ids=range(torch.cuda.device_count()))\n",
    "    netG.load_state_dict(torch.load('./checkpoints/G_imagenet.pth'))\n",
    "    netG.cuda()\n",
    "    netG.eval()\n",
    "    return netG\n",
    "\n",
    "def configuration():\n",
    "    config = Namespace()\n",
    "    config.target_type = 'Untargeted'\n",
    "    config.dataset_type = 'Cifar10'\n",
    "    config.target_model = 'resnet18'\n",
    "    config.iter = 50\n",
    "    config.max_epsilon = 100\n",
    "    config.image_size = 32\n",
    "    config.saving_root = './result/Greedyfool/untargeted/' + config.dataset_type + '/'\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### configuration\n",
    "config = configuration()\n",
    "\n",
    "##### Target model loading\n",
    "netT = target_net_factory(config.target_model)\n",
    "attack_algorithm = attack_factory('greedyfool_w')\n",
    "\n",
    "##### Generator loading for distortion map\n",
    "netG = GanGenerator(config.dataset_type)\n",
    "test_attack_success_rate(config, netT, attack_algorithm, generator=netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "13c6cff282055b12b410c0f9f59fed4afca4e230913126f1d565da59ed5ce96c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
